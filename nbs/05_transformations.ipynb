{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2357e16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d71f1d",
   "metadata": {},
   "source": [
    "# Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1068f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "from pyexpat import model\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numba import jit\n",
    "from scipy.stats import boxcox\n",
    "from scipy.special import inv_boxcox\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from numba import jit\n",
    "##Stationarity Check\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "# Box-Cox Transformation Utility Functions\n",
    "#------------------------------------------------------------------------------\n",
    "\n",
    "def box_cox_transform(x, shift=False, box_cox_lmda = None):\n",
    "    \"\"\"\n",
    "    Applies a Box-Cox transformation to a series x.\n",
    "\n",
    "    Args:\n",
    "        x (array-like): The input data.\n",
    "        shift (bool): add 1 to each element of data if True, default is False.\n",
    "        box_cox_lmda (float): The lambda parameter for the Box-Cox transformation.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (transformed data, updated lambda)\n",
    "    \"\"\"\n",
    "    if (box_cox_lmda == None):\n",
    "        if shift ==True:\n",
    "            transformed_data, lmbda = boxcox((np.array(x)+1))\n",
    "        else:\n",
    "            transformed_data, lmbda = boxcox(np.array(x))\n",
    "            \n",
    "    if (box_cox_lmda != None):\n",
    "        if shift ==True:\n",
    "            lmbda = box_cox_lmda\n",
    "            transformed_data = boxcox((np.array(x)+1), lmbda)\n",
    "        else:\n",
    "            lmbda = box_cox_lmda\n",
    "            transformed_data = boxcox(np.array(x), lmbda)\n",
    "    return transformed_data, lmbda\n",
    "\n",
    "\n",
    "def back_box_cox_transform(y_pred, lmda, shift=False, box_cox_biasadj=False):\n",
    "    \"\"\"\n",
    "    Inverse Box-Cox transform.\n",
    "\n",
    "    Args:\n",
    "        y_pred (array-like): Transformed forecast.\n",
    "        lmda (float): Box-Cox lambda.\n",
    "        shift (bool): Whether the original data was shifted.\n",
    "        box_cox_biasadj (bool): Whether bias adjustment is applied.\n",
    "    \n",
    "    Returns:\n",
    "        array-like: Back-transformed forecast.\n",
    "    \"\"\"\n",
    "    if (box_cox_biasadj==False):\n",
    "        if shift == True:\n",
    "            forecast = inv_boxcox(y_pred, lmda)-1\n",
    "        else:\n",
    "            forecast = inv_boxcox(y_pred, lmda)\n",
    "            \n",
    "    if (box_cox_biasadj== True):\n",
    "        pred_var = np.var(y_pred)\n",
    "        if shift == True:\n",
    "            if lmda ==0:\n",
    "                forecast = np.exp(y_pred)*(1+pred_var/2)-1\n",
    "            else:\n",
    "                forecast = ((lmda*y_pred+1)**(1/lmda))*(1+((1-lmda)*pred_var)/(2*((lmda*y_pred+1)**2)))-1\n",
    "        else:\n",
    "            if lmda ==0:\n",
    "                forecast = np.exp(y_pred)*(1+pred_var/2)\n",
    "            else:\n",
    "                forecast = ((lmda*y_pred+1)**(1/lmda))*(1+((1-lmda)*pred_var)/(2*((lmda*y_pred+1)**2)))\n",
    "    return forecast\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "# Differencing Utility Functions\n",
    "#------------------------------------------------------------------------------\n",
    "\n",
    "def undiff_ts(original_data, differenced_data, n):\n",
    "    \"\"\"\n",
    "    Inverts (ordinary) differencing.\n",
    "\n",
    "    Args:\n",
    "        original_data: The original time series.\n",
    "        differenced_data: The n-differenced series.\n",
    "        n (int): The degree of differencing.\n",
    "\n",
    "    Returns:\n",
    "        array-like: Undifferenced series.\n",
    "    \"\"\"\n",
    "    undiff_data = np.array(differenced_data)\n",
    "    if n > 1:\n",
    "        for i in range(n-1, 0, -1):\n",
    "            undiff_data = np.diff(original_data, i)[-1]+np.cumsum(undiff_data)\n",
    "    \n",
    "    return original_data[-1]+np.cumsum(undiff_data)\n",
    "\n",
    "def seasonal_diff(data, seasonal_period):\n",
    "    \"\"\"\n",
    "    Computes seasonal differences on array x.\n",
    "\n",
    "    Args:\n",
    "        x (array-like): The time series.\n",
    "        seasonal_period (int): The seasonal period.\n",
    "        \n",
    "    Returns:\n",
    "        array-like: Seasonally differenced time series.\n",
    "    \"\"\"\n",
    "    orig_data = list(np.repeat(np.nan, seasonal_period))+[data[i] - data[i - seasonal_period] for i in range(seasonal_period, len(data))]\n",
    "    return np.array(orig_data)\n",
    "\n",
    "def invert_seasonal_diff(orig_data, diff_data, seasonal_period):\n",
    "\n",
    "    \"\"\"\n",
    "    Inverts seasonal differencing.\n",
    "\n",
    "    Args:\n",
    "        orig (list): The original series values.\n",
    "        diff (array-like): The differenced series.\n",
    "        seasonal_period (int): The seasonal period.\n",
    "        \n",
    "    Returns:\n",
    "        array-like: Reconstructed series.\n",
    "    \"\"\"\n",
    "    # Start with the last seasonal_period original values\n",
    "    result = list(orig_data[-seasonal_period:])\n",
    "    for i in range(len(diff_data)):\n",
    "        # Each new value is previous season value + diff\n",
    "        val = diff_data[i] + result[i]\n",
    "        result.append(val)\n",
    "    # Only return the reconstructed values matching diff_data length\n",
    "    return np.array(result[seasonal_period:])\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "# Croston's Method metrics\n",
    "#------------------------------------------------------------------------------\n",
    "\n",
    "# @jit(nopython=True)\n",
    "def nzInterval(data, lag=0):\n",
    "    \"\"\"\n",
    "    Computes the intervals between non-zero values in a time series.\n",
    "\n",
    "    Args:\n",
    "        data (array-like): Input time series data.\n",
    "        lag (int): Number of lags to consider. Default is 0.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: An array of intervals between non-zero values, with NaNs for the first `lag` values.\n",
    "    \"\"\"\n",
    "    intervals = []\n",
    "    last_nonzero_times = []\n",
    "    if lag !=0:\n",
    "        arr = data[:-lag]\n",
    "    else:\n",
    "        arr = data\n",
    "\n",
    "    for i, j in enumerate(arr):\n",
    "        if j > 0.5:\n",
    "            last_nonzero_times.append(i)\n",
    "        \n",
    "        if len(last_nonzero_times)==1:\n",
    "            intervals.append(1)\n",
    "        else:\n",
    "            inter = last_nonzero_times[-1]-last_nonzero_times[-2]\n",
    "            intervals.append(inter)\n",
    "    \n",
    "    if lag !=0:\n",
    "        nas = list(np.repeat(np.nan, lag))\n",
    "        intervals = nas+intervals\n",
    "    return np.array(intervals)\n",
    "\n",
    "# @jit(nopython=True)\n",
    "def zeroCumulative(data, lag=0):\n",
    "    \"\"\"\n",
    "    Computes the cumulative count of consecutive zeros in a time series.\n",
    "    Args:\n",
    "        data (array-like): Input time series data.\n",
    "        lag (int): Number of lags to consider. Default is 0.\n",
    "    Returns:\n",
    "        numpy.ndarray: An array of cumulative counts of consecutive zeros, with NaNs for the first `lag` values.\n",
    "    \"\"\"\n",
    "    if lag !=0:\n",
    "        arr = data[:-lag]\n",
    "    else:\n",
    "        arr = data\n",
    "\n",
    "    count = 0\n",
    "    result = []\n",
    "    \n",
    "    for value in arr:\n",
    "        if value < 0.5:\n",
    "            count += 1\n",
    "        else:\n",
    "            count = 0\n",
    "        result.append(count)\n",
    "\n",
    "    if lag !=0:\n",
    "        nas = list(np.repeat(np.nan, lag))\n",
    "        result = nas+result\n",
    "    return np.array(result)\n",
    "\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "# Target Encoding Utility Functions\n",
    "#------------------------------------------------------------------------------\n",
    "\n",
    "def kfold_target_encoder(df, feature_col, target_col, n_splits=5):\n",
    "    \"\"\"\n",
    "    Perform K-fold target encoding for a given feature.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Input dataframe.\n",
    "        feature_col (str): Column name of the categorical feature.\n",
    "        target_col (str): Target column name.\n",
    "        n_splits (int): Number of folds for target encoding.\n",
    "\n",
    "    Returns:\n",
    "        np.array: Encoded target values.\n",
    "    \"\"\"\n",
    "    df_encoded = df.copy()\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    encoded_col_name = f\"{feature_col}_target_encoded\"\n",
    "    df_encoded[encoded_col_name] = np.nan\n",
    "    feat_idx = df_encoded.columns.get_loc(feature_col)\n",
    "    encode_idx = df_encoded.columns.get_loc(encoded_col_name)\n",
    "    # Perform KFold encoding\n",
    "    for train_idx, val_idx in kf.split(df):\n",
    "        # Calculate target mean per category using only the training fold\n",
    "        target_means = df.iloc[train_idx].groupby(feature_col)[target_col].mean()\n",
    "        # Map means to the validation fold\n",
    "        df_encoded.iloc[val_idx, encode_idx] = df_encoded.iloc[val_idx, feat_idx].map(target_means)\n",
    "    # Fill missing values with overall target mean\n",
    "    overall_mean = df[target_col].mean()\n",
    "    df_encoded[encoded_col_name].fillna(overall_mean, inplace=True)\n",
    "    return df_encoded[encoded_col_name].values\n",
    "\n",
    "def target_encoder_for_test(train_df, test_df, feature_col):\n",
    "    \"\"\"\n",
    "    Apply target encoding to the test set based on the training set.\n",
    "\n",
    "    Args:\n",
    "        train_df (pd.DataFrame): Training dataframe with encoded feature.\n",
    "        test_df (pd.DataFrame): Test dataframe.\n",
    "        feature_col (str): Column name to encode.\n",
    "\n",
    "    Returns:\n",
    "        np.array: Encoded values for the test set.\n",
    "    \"\"\"\n",
    "    encoded_col_name = f\"{feature_col}_target_encoded\"\n",
    "    target_means = train_df.groupby(feature_col)[encoded_col_name].mean()\n",
    "    overall_mean = train_df[encoded_col_name].mean()\n",
    "    test_encoded = test_df.copy()\n",
    "    test_encoded[encoded_col_name] = test_df[feature_col].map(target_means)\n",
    "    test_encoded[encoded_col_name].fillna(overall_mean, inplace=True)\n",
    "    return test_encoded[encoded_col_name].values\n",
    "\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "# Transformation Utility Functions\n",
    "#------------------------------------------------------------------------------\n",
    "\n",
    "def fourier_terms(\n",
    "    start_end_index: tuple,\n",
    "    period: int,\n",
    "    num_terms: int\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Generate Fourier terms (sine and cosine) for a given period and number of terms.\n",
    "\n",
    "    Args:\n",
    "        start_end_index (tuple): (start, end) defining the index.\n",
    "            - If integers: produces a RangeIndex from start to end (inclusive).\n",
    "            - If datetimes (strings or pd.Timestamp): produces a DatetimeIndex from start to end (inclusive, daily freq).\n",
    "        period (int): Seasonal period (e.g., 7 for weekly seasonality).\n",
    "        num_terms (int): Number of Fourier pairs (sine/cosine).\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame of Fourier terms indexed by generated index.\n",
    "    \"\"\"\n",
    "    start, end = start_end_index\n",
    "\n",
    "    # Decide index type\n",
    "    if isinstance(start, (int, np.integer)) and isinstance(end, (int, np.integer)):\n",
    "        index = pd.RangeIndex(start, end+1)  # exclusive of end\n",
    "        t = np.arange(len(index))\n",
    "    else:\n",
    "        # Convert to datetime if string given\n",
    "        start, end = pd.to_datetime(start), pd.to_datetime(end)\n",
    "        index = pd.date_range(start, end, freq=\"D\")\n",
    "        t = np.arange(len(index))\n",
    "\n",
    "    # Build Fourier terms\n",
    "    terms = {\n",
    "        f'sin_{k}_{period}': np.sin(2 * np.pi * k * t / period)\n",
    "        for k in range(1, num_terms + 1)\n",
    "    }\n",
    "    terms.update({\n",
    "        f'cos_{k}_{period}': np.cos(2 * np.pi * k * t / period)\n",
    "        for k in range(1, num_terms + 1)\n",
    "    })\n",
    "\n",
    "    return pd.DataFrame(terms, index=index)\n",
    "\n",
    "# @jit(nopython=True)\n",
    "# Your transformation classes\n",
    "class rolling_mean:\n",
    "    \"\"\"\n",
    "    A class to compute rolling mean with a specified window size and minimum samples.\n",
    "    Args:\n",
    "        shift (int): The number of periods to shift time series data.\n",
    "        window_size (int): The size of the rolling window.\n",
    "        min_samples (int): Minimum number of samples required to compute the mean.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, window_size, shift=1, min_samples=1):\n",
    "        self.shift = shift\n",
    "        self.window_size = window_size\n",
    "        self.min_samples = min_samples\n",
    "\n",
    "    def __call__(self, data, is_forecast=False):\n",
    "        \"\"\"\n",
    "        Compute the rolling mean of the data with the specified parameters.\n",
    "        Args:\n",
    "            data (pd.Series or np.ndarray): The input data to compute the rolling mean.\n",
    "            is_forecast (bool): If True, adjust the shift for forecasting purposes.\n",
    "        Returns:\n",
    "            pd.Series: The rolling mean of the input data.\n",
    "        \"\"\"\n",
    "\n",
    "        if is_forecast:\n",
    "            # For example, if it's a forecast, for the forecasting next value, we might want to shift by one less than usual to align with the forecasted period\n",
    "            return pd.Series(data).shift(self.shift-1).rolling(self.window_size, min_periods=self.min_samples).mean()\n",
    "        # If not a forecast, apply the usual shift\n",
    "        else:\n",
    "            # If not a forecast, apply the usual shift\n",
    "            return pd.Series(data).shift(self.shift).rolling(self.window_size, min_periods=self.min_samples).mean()\n",
    "        \n",
    "    def get_name(self):\n",
    "        return f\"rolling_mean_{self.window_size}_{self.shift}\"\n",
    "\n",
    "\n",
    "class rolling_quantile:\n",
    "    \"\"\"\n",
    "    A class to compute rolling quantile with a specified window size and minimum samples.\n",
    "    Args:\n",
    "        shift (int): The number of periods to shift time series data.\n",
    "        window_size (int): The size of the rolling window.\n",
    "        min_samples (int): Minimum number of samples required to compute the quantile.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, window_size, quantile, shift=1, min_samples=1):\n",
    "        self.shift = shift\n",
    "        self.window_size = window_size\n",
    "        self.quantile = quantile\n",
    "        self.min_samples = min_samples\n",
    "\n",
    "    def __call__(self, data, is_forecast=False):\n",
    "        # Return the rolling quantile with the specified window size and minimum samples\n",
    "        if is_forecast:\n",
    "            return pd.Series(data).shift(self.shift-1).rolling(self.window_size, min_periods=self.min_samples).quantile(self.quantile)\n",
    "        # If not a forecast, apply the usual shift\n",
    "        else:\n",
    "            # If not a forecast, apply the usual shift\n",
    "            return pd.Series(data).shift(self.shift).rolling(self.window_size, min_periods=self.min_samples).quantile(self.quantile)\n",
    "    def get_name(self):\n",
    "        return f\"rolling_quantile_{self.window_size}_{self.quantile}_{self.shift}\"\n",
    "    \n",
    "class rolling_std:\n",
    "    \"\"\"\n",
    "    A class to compute rolling std with a specified window size and minimum samples.\n",
    "    Args:\n",
    "        shift (int): The number of periods to shift time series data.\n",
    "        window_size (int): The size of the rolling window.\n",
    "        min_samples (int): Minimum number of samples required to compute the std.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, window_size, shift=1, min_samples=1):\n",
    "        self.shift = shift\n",
    "        self.window_size = window_size\n",
    "        self.min_samples = min_samples\n",
    "\n",
    "    def __call__(self, data, is_forecast=False):\n",
    "        # Return the rolling std with the specified window size and minimum samples\n",
    "        if is_forecast:\n",
    "            return pd.Series(data).shift(self.shift-1).rolling(self.window_size, min_periods=self.min_samples).std()\n",
    "        else:\n",
    "            return pd.Series(data).shift(self.shift).rolling(self.window_size, min_periods=self.min_samples).std()\n",
    "    def get_name(self):\n",
    "        return f\"rolling_std_{self.window_size}_{self.shift}\"   \n",
    "\n",
    "class expanding_std:\n",
    "    \"\"\"\n",
    "    A class to compute expanding standard deviation.\n",
    "    Args:\n",
    "        shift (int): The number of periods to shift time series data.\n",
    "    \"\"\"\n",
    "    def __init__(self, shift=1):\n",
    "        self.shift = shift\n",
    "    def __call__(self, data, is_forecast=False):\n",
    "        if is_forecast:\n",
    "            return pd.Series(data).shift(self.shift-1).expanding().std()\n",
    "        else:\n",
    "            return pd.Series(data).shift(self.shift).expanding().std()\n",
    "    def get_name(self):\n",
    "        return f\"expanding_std_{self.shift}\"\n",
    "\n",
    "class expanding_mean:\n",
    "    \"\"\"\n",
    "    A class to compute expanding mean.\n",
    "    Args:\n",
    "        shift (int): The number of periods to shift time series data.\n",
    "    \"\"\"\n",
    "    def __init__(self, shift=1):\n",
    "        self.shift = shift\n",
    "    def __call__(self, data, is_forecast=False):\n",
    "        if is_forecast:\n",
    "            return pd.Series(data).shift(self.shift-1).expanding().mean()\n",
    "        else:\n",
    "            return pd.Series(data).shift(self.shift).expanding().mean()\n",
    "    def get_name(self):\n",
    "        return f\"expanding_mean_{self.shift}\"\n",
    "\n",
    "class expanding_quantile:\n",
    "    \"\"\"\n",
    "    A class to compute expanding quantile.\n",
    "    Args:\n",
    "        quantile (float): The quantile to compute.\n",
    "    \"\"\"\n",
    "    def __init__(self, shift=1, quantile=0.5):\n",
    "        self.shift = shift\n",
    "        self.quantile = quantile\n",
    "\n",
    "    def __call__(self, data, is_forecast=False):\n",
    "        \"\"\"\n",
    "        Compute the expanding quantile.\n",
    "        \"\"\"\n",
    "        if is_forecast:\n",
    "            return pd.Series(data).shift(self.shift-1).expanding().quantile(self.quantile)\n",
    "        else:\n",
    "            return pd.Series(data).shift(self.shift).expanding().quantile(self.quantile)\n",
    "    def get_name(self):\n",
    "        return f\"expanding_quantile_{self.quantile}_{self.shift}\"   \n",
    "        \n",
    "class expanding_ets:\n",
    "    \"\"\"\n",
    "    A class to compute expanding ETS.\n",
    "    Args:\n",
    "        shift (int): The number of periods to shift time series data.\n",
    "        ets_params (dict): Parameters for the ExponentialSmoothing model.\n",
    "        fit_params (dict): Parameters for the fit method of the ExponentialSmoothing model.\n",
    "    \"\"\"\n",
    "    def __init__(self, ets_params, fit_params, shift=1):\n",
    "        self.shift = shift\n",
    "        self.ets_params = ets_params\n",
    "        self.fit_params = fit_params\n",
    "    def __call__(self, data, is_forecast=False):\n",
    "        if is_forecast:\n",
    "            self.shift -= 1\n",
    "        model_ = ExponentialSmoothing(pd.Series(data).shift(self.shift).dropna(), **self.ets_params).fit(**self.fit_params)\n",
    "        fitted = model_.fittedvalues\n",
    "        fitted_aligned = pd.Series(np.nan, index=data.index) # Align the index with the original data to avoid misalignment\n",
    "        fitted_aligned.iloc[self.shift:] = fitted.values\n",
    "        return fitted_aligned\n",
    "    \n",
    "    def get_name(self):\n",
    "        return f\"expanding_ets_{self.shift}\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
