{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130e04f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp probabilistic_forecasting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f430c9f",
   "metadata": {},
   "source": [
    "# Probabilistic forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a50b621",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from statsforecast.models import ARIMA, AutoARIMA, TBATS, AutoTBATS\n",
    "from peshbeen.model_selection import ParametricTimeSeriesSplit\n",
    "from scipy.stats import gaussian_kde\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "from statsmodels.tsa.api import VAR\n",
    "import copy\n",
    "rng_kde = np.random.default_rng(seed=42)\n",
    "\n",
    "# --------------------------------------------------------------------- \n",
    "# Helper functions and classes for probabilistic forecasting with conformal prediction\n",
    "# ---------------------------------------------------------------------\n",
    "# Generate conformal quantiles for future time steps\n",
    "\n",
    "def get_conformal_quantiles(non_conform, n_calib, quantiles, y_forecast):\n",
    "    \"\"\"\n",
    "    Generate conformal quantiles for future time steps.\n",
    "    Args:\n",
    "        non_conform: non-conformity scores from the conformal model\n",
    "        n_calib: number of calibration samples\n",
    "        quantiles (float or list): Quantiles to be calculated (e.g., 0.1, 0.5, 0.9).\n",
    "        y_forecast: point forecasts\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame containing point forecasts and conformal quantiles.\n",
    "    \"\"\"\n",
    "    if isinstance(quantiles, float):\n",
    "        if quantiles <0.5:\n",
    "            q= (1-2*quantiles)\n",
    "            q_which =np.ceil(q * (n_calib + 1)) / n_calib\n",
    "            quantile_ = np.quantile(non_conform, q_which, method=\"higher\", axis=1)\n",
    "            y_quantile = y_forecast - quantile_\n",
    "        elif quantiles == 0.5:\n",
    "            y_quantile = y_forecast\n",
    "        else:\n",
    "            q= (2*quantiles-1)\n",
    "            q_which = np.ceil(q * (n_calib + 1)) / n_calib\n",
    "            quantile_ = np.quantile(non_conform, q_which, method=\"higher\", axis=1)\n",
    "            y_quantile = y_forecast + quantile_\n",
    "        y_quantile = y_quantile[None, :]\n",
    "    elif isinstance(quantiles, list):\n",
    "        y_quantile = []\n",
    "        for quantile in quantiles:\n",
    "            if quantile < 0.5:\n",
    "                q= (1-2*quantile)\n",
    "                q_which = np.ceil(q * (n_calib + 1)) / n_calib # conformal quantile\n",
    "                quantile_ = np.quantile(non_conform, q_which, method=\"lower\", axis=1)\n",
    "                y_q = y_forecast - quantile_\n",
    "            elif quantile == 0.5:\n",
    "                y_q = y_forecast\n",
    "            else:\n",
    "                q= (2*quantile-1)\n",
    "                q_which = np.ceil(q * (n_calib + 1)) / n_calib # conformal quantile\n",
    "                quantile_ = np.quantile(non_conform, q_which, method=\"lower\", axis=1)\n",
    "                y_q = y_forecast + quantile_\n",
    "            y_quantile.append(y_q)\n",
    "        y_quantile = np.array(y_quantile)\n",
    "    \n",
    "    if isinstance(quantiles, float):\n",
    "        q_columns = [\"point_forecast\"]+[f'q_{int(quantiles*100)}']\n",
    "    elif isinstance(quantiles, list):\n",
    "        q_columns = [\"point_forecast\"]+[f'q_{int(quantile*100)}' for quantile in quantiles]\n",
    "    else:\n",
    "        raise ValueError(\"quantiles must be float or list of floats.\")\n",
    "    \n",
    "    return pd.DataFrame(np.concatenate((y_forecast[None, :], y_quantile), axis=0).T, columns=q_columns)\n",
    "\n",
    "def get_bootstrap_quantiles(samples, n_calib, quantiles, y_forecast):\n",
    "    \"\"\"\n",
    "    Generate bootstrap quantiles for future time steps.\n",
    "    Args:\n",
    "        samples: bootstrap samples from the predictive distribution\n",
    "        n_calib: number of calibration samples\n",
    "        quantiles (float or list): Quantiles to be calculated (e.g., 0.1, 0.5, 0.9).\n",
    "        y_forecast: point forecasts\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame containing point forecasts and conformal quantiles.\n",
    "    \"\"\"\n",
    "    if isinstance(quantiles, float):\n",
    "        q_which =np.ceil(quantiles * (n_calib + 1)) / n_calib \n",
    "        quantile_ = np.quantile(samples, q_which, method=\"higher\", axis=1)\n",
    "        y_quantile = quantile_[None, :]\n",
    "    elif isinstance(quantiles, list):\n",
    "        y_quantile = []\n",
    "        for quantile in quantiles:\n",
    "            q_which = np.ceil(quantile * (n_calib + 1)) / n_calib # conformal quantile\n",
    "            quantile_ = np.quantile(samples, q_which, method=\"lower\", axis=1)\n",
    "            y_quantile.append(quantile_)\n",
    "        y_quantile = np.array(y_quantile)\n",
    "    \n",
    "    if isinstance(quantiles, float):\n",
    "        q_columns = [\"point_forecast\"]+[f'q_{int(quantiles*100)}']\n",
    "    elif isinstance(quantiles, list):\n",
    "        q_columns = [\"point_forecast\"]+[f'q_{int(quantile*100)}' for quantile in quantiles]\n",
    "    else:\n",
    "        raise ValueError(\"quantiles must be float or list of floats.\")\n",
    "    \n",
    "    return pd.DataFrame(np.concatenate((y_forecast[None, :], y_quantile), axis=0).T, columns=q_columns)\n",
    "\n",
    "class ml_prob_forecasts():\n",
    "    \"\"\"\n",
    "    Probabilistic forecasting for ML models. It generates prediction intervals for future time steps and approximates distribution of predictions using Kernel Density Estimation (KDE).\n",
    "    Parameters:\n",
    "    - model: forecasting model to be used\n",
    "    - n_calibration: number of calibration windows\n",
    "    - H: forecast horizon\n",
    "    - sliding_window: size of the sliding window for cross-validation\n",
    "    - verbose: whether to print progress messages\n",
    "    \"\"\"\n",
    "    def __init__(self, model, n_calibration, H, sliding_window=1, verbose=False):\n",
    "        self.model = model\n",
    "        self.sliding_window = sliding_window\n",
    "        self.n_calib = n_calibration\n",
    "        self.verbose = verbose\n",
    "        self.H = H\n",
    "\n",
    "    def non_conformity_scores(self, df):\n",
    "        c_actuals, c_forecasts = [], []\n",
    "        # Create time series cross-validator that slides 1 time step for each training window\n",
    "        tscv = ParametricTimeSeriesSplit(n_splits=self.n_calib, test_size=self.H, step_size=self.sliding_window)\n",
    "        for train_index, test_index in tscv.split(df):\n",
    "            train, test = df.iloc[train_index], df.iloc[test_index]\n",
    "            x_test = test.drop(columns=[self.model.target_col])\n",
    "            y_test = np.array(test[self.model.target_col])\n",
    "            self.model.fit(train)\n",
    "            H_forecasts = self.model.forecast(self.H, x_test)\n",
    "            c_forecasts.append(H_forecasts)\n",
    "            c_actuals.append(y_test)\n",
    "            if self.verbose:\n",
    "                print(f\"Completed calibration window {len(c_forecasts)} out of {self.n_calib}\")\n",
    "        self.resid = np.column_stack(c_actuals) - np.column_stack(c_forecasts) # Residuals n_calib*H\n",
    "        self.non_conform = np.abs(self.resid) # non-conformity scores\n",
    "        self.c_actuals = np.column_stack(c_actuals)\n",
    "        self.c_forecasts = np.column_stack(c_forecasts)\n",
    "\n",
    "        \n",
    "    def calculate_quantile(self, scores_calib):\n",
    "        # Vectorized quantile calculation for list delta\n",
    "        if isinstance(self.delta, float):\n",
    "            which_quantile = np.ceil(self.delta * (self.n_calib + 1)) / self.n_calib\n",
    "            return np.quantile(scores_calib, which_quantile, method=\"lower\", axis=0)\n",
    "        elif isinstance(self.delta, list):\n",
    "            which_quantiles = np.ceil(np.array(self.delta) * (self.n_calib + 1)) / self.n_calib\n",
    "            return np.array([np.quantile(scores_calib, q, method=\"lower\", axis=0) for q in which_quantiles])\n",
    "        else:\n",
    "            raise ValueError(\"delta must be float or list of floats.\")\n",
    "    \n",
    "    \n",
    "    def calibrate(self, df, delta = 0.5):\n",
    "        \"\"\"\n",
    "        Calibrate the conformal model using the calibration dataset.\n",
    "        Args:\n",
    "            df (pd.DataFrame): DataFrame containing the calibration data.\n",
    "            delta (float or list): Significance level(s) for the prediction intervals.\n",
    "        \"\"\"\n",
    "        self.delta = delta\n",
    "        self.non_conformity_scores(df=df)\n",
    "        h_quantiles = []\n",
    "        for i in range(self.H):\n",
    "            q_hat = self.calculate_quantile(self.non_conform[i])\n",
    "            h_quantiles.append(q_hat)\n",
    "        self.q_hat_D = np.array(h_quantiles)\n",
    "\n",
    "    # Generate prediction intervals using the calibrated quantiles\n",
    "\n",
    "    def generate_prediction_intervals(self, df, future_exog=None):\n",
    "        '''\n",
    "        Generate conformal prediction intervals for the forecasted values.\n",
    "        Args:\n",
    "            df (pd.DataFrame): DataFrame containing the training data.\n",
    "            future_exog (pd.DataFrame, optional): Future exogenous variables for forecasting.\n",
    "        '''\n",
    "        # Only calibrate if not already done\n",
    "        if not hasattr(self, 'q_hat_D'):\n",
    "            raise RuntimeError(\"Conformalizer must be calibrated before generating prediction intervals. Run .calibrate(df_calibration) first.\")\n",
    "        self.model.fit(df)\n",
    "        if future_exog is not None:\n",
    "            y_forecast = np.array(self.model.forecast(self.H, future_exog))\n",
    "        else:\n",
    "            y_forecast = np.array(self.model.forecast(self.H))\n",
    "        result = [y_forecast]\n",
    "        col_names = [\"point_forecast\"]\n",
    "\n",
    "        if isinstance(self.delta, float):\n",
    "            y_lower, y_upper = y_forecast - self.q_hat_D, y_forecast + self.q_hat_D\n",
    "            result.extend([y_lower, y_upper])\n",
    "            col_names.extend([f'lower_{int(self.delta*100)}', f'upper_{int(self.delta*100)}'])\n",
    "        elif isinstance(self.delta, list):\n",
    "            for idx, d in enumerate(self.delta):\n",
    "                y_lower = y_forecast - self.q_hat_D[:, idx]\n",
    "                y_upper = y_forecast + self.q_hat_D[:, idx]\n",
    "                result.extend([y_lower, y_upper])\n",
    "                col_names.extend([f'lower_{int(d*100)}', f'upper_{int(d*100)}'])\n",
    "        # distributions for each horizons. So add y_forecast array to each columns of self.resid and equal to self.dist\n",
    "        dist = y_forecast[:, None] + self.resid\n",
    "        self.dist = pd.DataFrame(dist.T, columns=[f'h_{i+1}' for i in range(self.H)])\n",
    "        self.dist = self.dist.clip(lower=0.1)\n",
    "        return pd.DataFrame(np.column_stack(result), columns=col_names)\n",
    "        \n",
    "    def conformal_quantiles(self, df, quantiles, future_exog=None):\n",
    "        \"\"\"\n",
    "        Generate conformal quantiles for future time steps.\n",
    "        Args:\n",
    "            df (pd.DataFrame): DataFrame containing the training data.\n",
    "            quantiles (float or list): Quantiles to be calculated (e.g., 0.1, 0.5, 0.9).\n",
    "            future_exog (pd.DataFrame, optional): Future exogenous variables for forecasting.\n",
    "        Returns:\n",
    "            pd.DataFrame: DataFrame containing point forecasts and conformal quantiles.\n",
    "        \"\"\"\n",
    "        # Only calibrate if not already done\n",
    "        if not hasattr(self, 'q_hat_D'):\n",
    "            raise RuntimeError(\"Conformalizer must be calibrated before generating prediction intervals. Run .calibrate(df_calibration) first.\")\n",
    "        self.model.fit(df)\n",
    "        if future_exog is not None:\n",
    "            y_forecast = np.array(self.model.forecast(self.H, future_exog))\n",
    "        else:\n",
    "            y_forecast = np.array(self.model.forecast(self.H))\n",
    "\n",
    "        return get_conformal_quantiles(self.non_conform, self.n_calib, quantiles, y_forecast)\n",
    "\n",
    "    def bootstrap(self, df, samples=1000, future_exog=None, approximate=\"kde\"):\n",
    "        \"\"\"\n",
    "        Generate samples from the predictive distribution generated by residuals from conformal prediction.\n",
    "        The samples are drawn from a Gaussian kernel density estimate of the residuals.\n",
    "        \"\"\"\n",
    "        # Return a random sample from Gaussian Kernel density estimation\n",
    "        if not hasattr(self, 'resid'):\n",
    "            raise RuntimeError(\"Residuals not available. Run .non_conformity_scores(df) .calibrate(df) or  first.\")\n",
    "        self.model.fit(df)\n",
    "        if future_exog is not None:\n",
    "            y_forecast = np.array(self.model.forecast(self.H, future_exog))\n",
    "        else:\n",
    "            y_forecast = np.array(self.model.forecast(self.H))\n",
    "\n",
    "        # self.bootstrap_forecasts = np.column_stack([[gaussian_kde(self.resid[i]).resample(size=1)[0][0]+y_forecast[i]\n",
    "        #                                    for i in range(self.H)] for _ in range(samples)]) # H x samples\n",
    "\n",
    "        # ✅ Create a deep copy so that we don’t overwrite self\n",
    "        new_instance = copy.deepcopy(self)\n",
    "        if approximate == \"kde\":\n",
    "            new_instance.bootstrap_forecasts = np.column_stack([[gaussian_kde(new_instance.resid[i]).resample(size=samples, seed=rng_kde)+y_forecast[i]]\n",
    "                                        for i in range(new_instance.H)])[0] # H x samples\n",
    "        elif approximate == \"empirical\":\n",
    "            new_instance.bootstrap_forecasts = np.column_stack([np.random.choice(new_instance.resid[i], size=samples, replace=True)+y_forecast[i]\n",
    "                for i in range(self.H)]).T\n",
    "        else:\n",
    "            raise ValueError(\"approximate must be 'kde' or 'empirical'.\")\n",
    "\n",
    "        new_instance.bootstrap_forecasts_df = pd.DataFrame(new_instance.bootstrap_forecasts.T, columns=[f'h_{i+1}' for i in range(self.H)])\n",
    "        new_instance.y_forecast_b = y_forecast\n",
    "\n",
    "        return new_instance\n",
    "\n",
    "    def bootstrap_quantiles(self, quantiles, bootstrap_method='bootstrap'):\n",
    "        \"\"\"\n",
    "        Generate bootstrap quantiles for future time steps.\n",
    "        Args:\n",
    "            quantiles (float or list): Quantiles to be calculated (e.g., 0.1, 0.5, 0.9).\n",
    "            bootstrap_method (str): The method to use for bootstrapping or simulated correlated_forecasts ('bootstrap' or 'correlated').\n",
    "        \"\"\"\n",
    "        ## Make sure bootstrap() method is called before calling this method\n",
    "        if bootstrap_method == 'bootstrap':\n",
    "            if (not hasattr(self, 'bootstrap')):\n",
    "                raise RuntimeError(\"Bootstrap samples not available. Run .bootstrap(df) first.\")\n",
    "            return get_bootstrap_quantiles(self.bootstrap_forecasts, self.n_calib, quantiles, self.y_forecast_b)\n",
    "        elif bootstrap_method == 'correlated':\n",
    "            if (not hasattr(self, 'simulate_correlated_forecasts')):\n",
    "                raise RuntimeError(\"Correlated forecast samples not available. Run .simulate_correlated_forecasts(df) first.\")\n",
    "            return get_bootstrap_quantiles(self.w_samples.T, self.n_calib, quantiles, self.y_forecast_c)\n",
    "\n",
    "    def simulate_correlated_forecasts(self, df, samples=1000, future_exog=None):\n",
    "        \"\"\"\n",
    "        Simulate correlated errors to generate forecasts\n",
    "        Parameters:\n",
    "        - df: DataFrame containing the training data\n",
    "        - samples: number of samples to generate\n",
    "        - future_exog: optional exogenous variables for forecasting\n",
    "        Returns:\n",
    "        - DataFrame containing the simulated forecasts\n",
    "        \"\"\"\n",
    "        if not hasattr(self, 'resid'):\n",
    "            raise RuntimeError(\"Residuals not available. Run .non_conformity_scores(df) .calibrate(df) or  first.\")\n",
    "        self.model.fit(df)\n",
    "        if future_exog is not None:\n",
    "            y_forecast = np.array(self.model.forecast(self.H, future_exog))\n",
    "        else:\n",
    "            y_forecast = np.array(self.model.forecast(self.H))\n",
    "\n",
    "        mu = np.mean(self.resid.T, axis=0)\n",
    "        sigma_ = np.cov(self.resid.T, rowvar=False, ddof=1)\n",
    "        rng = np.random.default_rng(seed=42)\n",
    "        samples = rng.multivariate_normal(mu, sigma_, size=samples)\n",
    "        self.w_samples = samples + y_forecast\n",
    "        self.correlated_forecasts = pd.DataFrame(self.w_samples, columns=[f'h_{i+1}' for i in range(self.H)])\n",
    "        self.y_forecast_c = y_forecast\n",
    "        return self\n",
    "\n",
    "class var_prob_forecasts():\n",
    "    \"\"\"\n",
    "    Probabilistic forecasting for vector autoregressive time series forecasting.\n",
    "    It generates prediction intervals for future time steps and approximates distribution of predictions using Kernel Density Estimation (KDE).\n",
    "    Parameters:\n",
    "    - model: forecasting model to be used\n",
    "    - target_col: one of the target columns in multivariate time series should be specified for conformalization\n",
    "    - n_calibration: number of calibration windows\n",
    "    - H: forecast horizon\n",
    "    - sliding_window: size of the sliding window for cross-validation\n",
    "    - verbose: whether to print progress messages\n",
    "    \"\"\"\n",
    "    def __init__(self, model, target_col, n_calibration, H, sliding_window=1, verbose=False):\n",
    "        self.model = model\n",
    "        self.tar_col = target_col\n",
    "        self.sliding_window = sliding_window\n",
    "        self.n_calib = n_calibration\n",
    "        self.verbose = verbose\n",
    "        self.H = H\n",
    "\n",
    "    def non_conformity_scores(self, df):\n",
    "        c_actuals, c_forecasts = [], []\n",
    "        # Create time series cross-validator that slides 1 time step for each training window\n",
    "        tscv = ParametricTimeSeriesSplit(n_splits=self.n_calib, test_size=self.H, step_size=self.sliding_window)\n",
    "        for train_index, test_index in tscv.split(df):\n",
    "            train, test = df.iloc[train_index], df.iloc[test_index]\n",
    "            x_test = test.drop(columns=self.model.target_cols)\n",
    "            y_test = np.array(test[self.tar_col])\n",
    "            self.model.fit(train)\n",
    "            H_forecasts = self.model.forecast(self.H, x_test)[self.tar_col]\n",
    "            c_forecasts.append(H_forecasts)\n",
    "            c_actuals.append(y_test)\n",
    "            if self.verbose:\n",
    "                print(f\"Completed calibration window {len(c_forecasts)} out of {self.n_calib}\")\n",
    "        self.resid = np.column_stack(c_actuals) - np.column_stack(c_forecasts) # Residuals n_calib*H\n",
    "        self.non_conform = np.abs(self.resid) # non-conformity scores\n",
    "        self.c_actuals = np.column_stack(c_actuals)\n",
    "        self.c_forecasts = np.column_stack(c_forecasts)\n",
    "        \n",
    "    def calculate_quantile(self, scores_calib):\n",
    "        # Vectorized quantile calculation for list delta\n",
    "        if isinstance(self.delta, float):\n",
    "            which_quantile = np.ceil(self.delta * (self.n_calib + 1)) / self.n_calib\n",
    "            return np.quantile(scores_calib, which_quantile, method=\"lower\", axis=0)\n",
    "        elif isinstance(self.delta, list):\n",
    "            which_quantiles = np.ceil(np.array(self.delta) * (self.n_calib + 1)) / self.n_calib\n",
    "            return np.array([np.quantile(scores_calib, q, method=\"lower\", axis=0) for q in which_quantiles])\n",
    "        else:\n",
    "            raise ValueError(\"delta must be float or list of floats.\")\n",
    "    \n",
    "    \n",
    "    def calibrate(self, df, delta = 0.5):\n",
    "        \"\"\"\n",
    "        Calibrate the conformal model using the calibration dataset.\n",
    "        Args:\n",
    "            df (pd.DataFrame): DataFrame containing the calibration data.\n",
    "            delta (float or list): Significance level(s) for the prediction intervals.\n",
    "        \"\"\"\n",
    "        self.delta = delta\n",
    "        self.non_conformity_scores(df=df)\n",
    "        h_quantiles = []\n",
    "        for i in range(self.H):\n",
    "            q_hat = self.calculate_quantile(self.non_conform[i])\n",
    "            h_quantiles.append(q_hat)\n",
    "        self.q_hat_D = np.array(h_quantiles)\n",
    "\n",
    "    # Generate prediction intervals using the calibrated quantiles\n",
    "\n",
    "    def generate_prediction_intervals(self, df, future_exog=None):\n",
    "        '''\n",
    "        Generate conformal prediction intervals for the forecasted values.\n",
    "        Args:\n",
    "            df (pd.DataFrame): DataFrame containing the training data.\n",
    "            future_exog (pd.DataFrame, optional): Future exogenous variables for forecasting.\n",
    "        '''\n",
    "        # Only calibrate if not already done\n",
    "        if not hasattr(self, 'q_hat_D'):\n",
    "            raise RuntimeError(\"Conformalizer must be calibrated before generating prediction intervals. Run .calibrate(df_calibration) first.\")\n",
    "        self.model.fit(df)\n",
    "        if future_exog is not None:\n",
    "            y_forecast = np.array(self.model.forecast(self.H, future_exog)[self.tar_col])\n",
    "        else:\n",
    "            y_forecast = np.array(self.model.forecast(self.H)[self.tar_col])\n",
    "        result = [y_forecast]\n",
    "        col_names = [\"point_forecast\"]\n",
    "\n",
    "        if isinstance(self.delta, float):\n",
    "            y_lower, y_upper = y_forecast - self.q_hat_D, y_forecast + self.q_hat_D\n",
    "            result.extend([y_lower, y_upper])\n",
    "            col_names.extend([f'lower_{int(self.delta*100)}', f'upper_{int(self.delta*100)}'])\n",
    "        elif isinstance(self.delta, list):\n",
    "            for idx, d in enumerate(self.delta):\n",
    "                y_lower = y_forecast - self.q_hat_D[:, idx]\n",
    "                y_upper = y_forecast + self.q_hat_D[:, idx]\n",
    "                result.extend([y_lower, y_upper])\n",
    "                col_names.extend([f'lower_{int(d*100)}', f'upper_{int(d*100)}'])\n",
    "        # distributions for each horizons. So add y_forecast array to each columns of self.resid and equal to self.dist\n",
    "        dist = y_forecast[:, None] + self.resid\n",
    "        self.dist = pd.DataFrame(dist.T, columns=[f'h_{i+1}' for i in range(self.H)])\n",
    "        self.dist = self.dist.clip(lower=0.1)\n",
    "        return pd.DataFrame(np.column_stack(result), columns=col_names)\n",
    "\n",
    "\n",
    "    def conformal_quantiles(self, df, quantiles, future_exog=None):\n",
    "        \"\"\"\n",
    "        Generate conformal quantiles for future time steps.\n",
    "        Args:\n",
    "            df (pd.DataFrame): DataFrame containing the training data.\n",
    "            quantiles (float or list): Quantiles to be calculated (e.g., 0.1, 0.5, 0.9).\n",
    "            future_exog (pd.DataFrame, optional): Future exogenous variables for forecasting.\n",
    "        Returns:\n",
    "            pd.DataFrame: DataFrame containing point forecasts and conformal quantiles.\n",
    "        \"\"\"\n",
    "        # Only calibrate if not already done\n",
    "        if not hasattr(self, 'q_hat_D'):\n",
    "            raise RuntimeError(\"Conformalizer must be calibrated before generating prediction intervals. Run .calibrate(df_calibration) first.\")\n",
    "        self.model.fit(df)\n",
    "        if future_exog is not None:\n",
    "            y_forecast = np.array(self.model.forecast(self.H, future_exog)[self.tar_col])\n",
    "        else:\n",
    "            y_forecast = np.array(self.model.forecast(self.H)[self.tar_col])\n",
    "\n",
    "        return get_conformal_quantiles(self.non_conform, self.n_calib, quantiles, y_forecast)\n",
    "\n",
    "    def bootstrap(self, df, samples=1000, future_exog=None , approximate=\"kde\"):\n",
    "        \"\"\"\n",
    "        Generate samples from the predictive distribution generated by residuals from conformal prediction.\n",
    "        The samples are drawn from a Gaussian kernel density estimate of the residuals.\n",
    "        \"\"\"\n",
    "        # Return a random sample from Gaussian Kernel density estimation\n",
    "        if not hasattr(self, 'resid'):\n",
    "            raise RuntimeError(\"Residuals not available. Run .non_conformity_scores(df) .calibrate(df) or  first.\")\n",
    "        self.model.fit(df)\n",
    "        if future_exog is not None:\n",
    "            y_forecast = np.array(self.model.forecast(self.H, future_exog)[self.tar_col])\n",
    "        else:\n",
    "            y_forecast = np.array(self.model.forecast(self.H)[self.tar_col])\n",
    "\n",
    "        # ✅ Create a deep copy so that we don’t overwrite self\n",
    "        new_instance = copy.deepcopy(self)\n",
    "        if approximate == \"kde\":\n",
    "            new_instance.bootstrap_forecasts = np.column_stack([[gaussian_kde(new_instance.resid[i]).resample(size=samples, seed=rng_kde)+y_forecast[i]]\n",
    "                                        for i in range(new_instance.H)])[0] # H x samples\n",
    "        elif approximate == \"empirical\":\n",
    "            new_instance.bootstrap_forecasts = np.column_stack([np.random.choice(new_instance.resid[i], size=samples, replace=True)+y_forecast[i]\n",
    "                for i in range(self.H)]).T\n",
    "        else:\n",
    "            raise ValueError(\"approximate must be 'kde' or 'empirical'.\")\n",
    "\n",
    "        new_instance.bootstrap_forecasts_df = pd.DataFrame(new_instance.bootstrap_forecasts.T, columns=[f'h_{i+1}' for i in range(self.H)])\n",
    "        new_instance.y_forecast_b = y_forecast\n",
    "\n",
    "        return new_instance\n",
    "\n",
    "    def bootstrap_quantiles(self, quantiles, bootstrap_method='bootstrap'):\n",
    "        \"\"\"\n",
    "        Generate bootstrap quantiles for future time steps.\n",
    "        Args:\n",
    "            quantiles (float or list): Quantiles to be calculated (e.g., 0.1, 0.5, 0.9).\n",
    "            bootstrap_method (str): The method to use for bootstrapping or simulated correlated_forecasts ('bootstrap' or 'correlated').\n",
    "        \"\"\"\n",
    "        ## Make sure bootstrap() method is called before calling this method\n",
    "        if bootstrap_method == 'bootstrap':\n",
    "            if (not hasattr(self, 'bootstrap')):\n",
    "                raise RuntimeError(\"Bootstrap samples not available. Run .bootstrap(df) first.\")\n",
    "            return get_bootstrap_quantiles(self.bootstrap_forecasts, self.n_calib, quantiles, self.y_forecast_b)\n",
    "        elif bootstrap_method == 'correlated':\n",
    "            if (not hasattr(self, 'simulate_correlated_forecasts')):\n",
    "                raise RuntimeError(\"Correlated forecast samples not available. Run .simulate_correlated_forecasts(df) first.\")\n",
    "            return get_bootstrap_quantiles(self.w_samples.T, self.n_calib, quantiles, self.y_forecast_c)\n",
    "    \n",
    "    def simulate_correlated_forecasts(self, df, samples=1000, future_exog=None):\n",
    "        \"\"\"\n",
    "        Simulate correlated errors to generate forecasts\n",
    "        Parameters:\n",
    "        - df: DataFrame containing the training data\n",
    "        - samples: number of samples to generate\n",
    "        - future_exog: optional exogenous variables for forecasting\n",
    "        Returns:\n",
    "        - DataFrame containing the simulated forecasts\n",
    "        \"\"\"\n",
    "        if not hasattr(self, 'resid'):\n",
    "            raise RuntimeError(\"Residuals not available. Run .non_conformity_scores(df) .calibrate(df) or  first.\")\n",
    "        self.model.fit(df)\n",
    "        if future_exog is not None:\n",
    "            y_forecast = np.array(self.model.forecast(self.H, future_exog)[self.tar_col])\n",
    "        else:\n",
    "            y_forecast = np.array(self.model.forecast(self.H)[self.tar_col])\n",
    "\n",
    "        mu = np.mean(self.resid.T, axis=0)\n",
    "        sigma_ = np.cov(self.resid.T, rowvar=False, ddof=1)\n",
    "        rng = np.random.default_rng(seed=42)\n",
    "        samples = rng.multivariate_normal(mu, sigma_, size=samples)\n",
    "        self.w_samples = samples + y_forecast\n",
    "        self.correlated_forecasts = pd.DataFrame(self.w_samples, columns=[f'h_{i+1}' for i in range(self.H)])\n",
    "        self.y_forecast_c = y_forecast\n",
    "        return self\n",
    "    \n",
    "class hmm_prob_forecasts():\n",
    "    \"\"\"\n",
    "    Probabilistic forecasting for Markov Switching Regression. It generates prediction intervals for future time steps and approximates distribution of predictions using Kernel Density Estimation (KDE).\n",
    "    Parameters:\n",
    "    - model: forecasting model to be used\n",
    "    - n_calibration: number of calibration windows\n",
    "    - H: forecast horizon\n",
    "    - sliding_window: size of the sliding window for cross-validation\n",
    "    - n_iter: number of iterations for HMM fitting\n",
    "    - verbose: whether to print progress messages\n",
    "    \"\"\"\n",
    "    def __init__(self, model, n_calibration, H, sliding_window=1, n_iter=1, verbose=False):\n",
    "        self.model = model\n",
    "        self.sliding_window = sliding_window\n",
    "        self.n_calib = n_calibration\n",
    "        self.n_iter = n_iter\n",
    "        self.verbose = verbose\n",
    "        self.H = H\n",
    "\n",
    "    def non_conformity_scores(self, df):\n",
    "        c_actuals, c_forecasts = [], []\n",
    "        # Create time series cross-validator that slides 1 time step for each training window\n",
    "        tscv = ParametricTimeSeriesSplit(n_splits=self.n_calib, test_size=self.H, step_size=self.sliding_window)\n",
    "        for train_index, test_index in tscv.split(df):\n",
    "            train, test = df.iloc[train_index], df.iloc[test_index]\n",
    "            x_test = test.drop(columns=[self.model.target_col])\n",
    "            y_test = np.array(test[self.model.target_col])\n",
    "            self.model.fit(train, self.n_iter)\n",
    "            H_forecasts = self.model.forecast(self.H, x_test)\n",
    "            c_forecasts.append(H_forecasts)\n",
    "            c_actuals.append(y_test)\n",
    "            if self.verbose:\n",
    "                print(f\"Completed calibration window {len(c_forecasts)} out of {self.n_calib}\")\n",
    "        self.resid = np.column_stack(c_actuals) - np.column_stack(c_forecasts) # Residuals n_calib*H\n",
    "        self.non_conform = np.abs(self.resid) # non-conformity scores\n",
    "        self.c_actuals = np.column_stack(c_actuals)\n",
    "        self.c_forecasts = np.column_stack(c_forecasts)\n",
    "\n",
    "        \n",
    "    def calculate_quantile(self, scores_calib):\n",
    "        # Vectorized quantile calculation for list delta\n",
    "        if isinstance(self.delta, float):\n",
    "            which_quantile = np.ceil(self.delta * (self.n_calib + 1)) / self.n_calib\n",
    "            return np.quantile(scores_calib, which_quantile, method=\"lower\", axis=0)\n",
    "        elif isinstance(self.delta, list):\n",
    "            which_quantiles = np.ceil(np.array(self.delta) * (self.n_calib + 1)) / self.n_calib\n",
    "            return np.array([np.quantile(scores_calib, q, method=\"lower\", axis=0) for q in which_quantiles])\n",
    "        else:\n",
    "            raise ValueError(\"delta must be float or list of floats.\")\n",
    "    \n",
    "    \n",
    "    def calibrate(self, df, delta = 0.5):\n",
    "        \"\"\"\n",
    "        Calibrate the conformal model using the calibration dataset.\n",
    "        Args:\n",
    "            df (pd.DataFrame): DataFrame containing the calibration data.\n",
    "            delta (float or list): Significance level(s) for the prediction intervals.\n",
    "        \"\"\"\n",
    "        self.delta = delta\n",
    "        self.non_conformity_scores(df=df)\n",
    "        h_quantiles = []\n",
    "        for i in range(self.H):\n",
    "            q_hat = self.calculate_quantile(self.non_conform[i])\n",
    "            h_quantiles.append(q_hat)\n",
    "        self.q_hat_D = np.array(h_quantiles)\n",
    "\n",
    "    # Generate prediction intervals using the calibrated quantiles\n",
    "\n",
    "    def generate_prediction_intervals(self, df, future_exog=None):\n",
    "        '''\n",
    "        Generate conformal prediction intervals for the forecasted values.\n",
    "        Args:\n",
    "            df (pd.DataFrame): DataFrame containing the training data.\n",
    "            future_exog (pd.DataFrame, optional): Future exogenous variables for forecasting.\n",
    "        '''\n",
    "        # Only calibrate if not already done\n",
    "        if not hasattr(self, 'q_hat_D'):\n",
    "            raise RuntimeError(\"Conformalizer must be calibrated before generating prediction intervals. Run .calibrate(df_calibration) first.\")\n",
    "        self.model.fit(df, self.n_iter)\n",
    "        if future_exog is not None:\n",
    "            y_forecast = np.array(self.model.forecast(self.H, future_exog))\n",
    "        else:\n",
    "            y_forecast = np.array(self.model.forecast(self.H))\n",
    "        result = [y_forecast]\n",
    "        col_names = [\"point_forecast\"]\n",
    "\n",
    "        if isinstance(self.delta, float):\n",
    "            y_lower, y_upper = y_forecast - self.q_hat_D, y_forecast + self.q_hat_D\n",
    "            result.extend([y_lower, y_upper])\n",
    "            col_names.extend([f'lower_{int(self.delta*100)}', f'upper_{int(self.delta*100)}'])\n",
    "        elif isinstance(self.delta, list):\n",
    "            for idx, d in enumerate(self.delta):\n",
    "                y_lower = y_forecast - self.q_hat_D[:, idx]\n",
    "                y_upper = y_forecast + self.q_hat_D[:, idx]\n",
    "                result.extend([y_lower, y_upper])\n",
    "                col_names.extend([f'lower_{int(d*100)}', f'upper_{int(d*100)}'])\n",
    "        # distributions for each horizons. So add y_forecast array to each columns of self.resid and equal to self.dist\n",
    "        dist = y_forecast[:, None] + self.resid\n",
    "        self.dist = pd.DataFrame(dist.T, columns=[f'h_{i+1}' for i in range(self.H)])\n",
    "        self.dist = self.dist.clip(lower=0.1)\n",
    "        return pd.DataFrame(np.column_stack(result), columns=col_names)\n",
    "\n",
    "    def conformal_quantiles(self, df, quantiles, future_exog=None):\n",
    "        \"\"\"\n",
    "        Generate conformal quantiles for future time steps.\n",
    "        Args:\n",
    "            df (pd.DataFrame): DataFrame containing the training data.\n",
    "            quantiles (float or list): Quantiles to be calculated (e.g., 0.1, 0.5, 0.9).\n",
    "            future_exog (pd.DataFrame, optional): Future exogenous variables for forecasting.\n",
    "        Returns:\n",
    "            pd.DataFrame: DataFrame containing point forecasts and conformal quantiles.\n",
    "        \"\"\"\n",
    "        # Only calibrate if not already done\n",
    "        if not hasattr(self, 'q_hat_D'):\n",
    "            raise RuntimeError(\"Conformalizer must be calibrated before generating prediction intervals. Run .calibrate(df_calibration) first.\")\n",
    "        self.model.fit(df, self.n_iter)\n",
    "        if future_exog is not None:\n",
    "            y_forecast = np.array(self.model.forecast(self.H, future_exog))\n",
    "        else:\n",
    "            y_forecast = np.array(self.model.forecast(self.H))\n",
    "\n",
    "        return get_conformal_quantiles(self.non_conform, self.n_calib, quantiles, y_forecast)\n",
    "\n",
    "    def bootstrap(self, df, samples=1000, future_exog=None , approximate=\"kde\"):\n",
    "        \"\"\"\n",
    "        Generate samples from the predictive distribution generated by residuals from conformal prediction.\n",
    "        The samples are drawn from a Gaussian kernel density estimate of the residuals.\n",
    "        \"\"\"\n",
    "        # Return a random sample from Gaussian Kernel density estimation\n",
    "        if not hasattr(self, 'resid'):\n",
    "            raise RuntimeError(\"Residuals not available. Run .non_conformity_scores(df) .calibrate(df) or  first.\")\n",
    "        self.model.fit(df, self.n_iter)\n",
    "        if future_exog is not None:\n",
    "            y_forecast = np.array(self.model.forecast(self.H, future_exog))\n",
    "        else:\n",
    "            y_forecast = np.array(self.model.forecast(self.H))\n",
    "\n",
    "        # ✅ Create a deep copy so that we don’t overwrite self\n",
    "        new_instance = copy.deepcopy(self)\n",
    "        if approximate == \"kde\":\n",
    "            new_instance.bootstrap_forecasts = np.column_stack([[gaussian_kde(new_instance.resid[i]).resample(size=samples, seed=rng_kde)+y_forecast[i]]\n",
    "                                        for i in range(new_instance.H)])[0] # H x samples\n",
    "        elif approximate == \"empirical\":\n",
    "            new_instance.bootstrap_forecasts = np.column_stack([np.random.choice(new_instance.resid[i], size=samples, replace=True)+y_forecast[i]\n",
    "                for i in range(self.H)]).T\n",
    "        else:\n",
    "            raise ValueError(\"approximate must be 'kde' or 'empirical'.\")\n",
    "\n",
    "        new_instance.bootstrap_forecasts_df = pd.DataFrame(new_instance.bootstrap_forecasts.T, columns=[f'h_{i+1}' for i in range(self.H)])\n",
    "        new_instance.y_forecast_b = y_forecast\n",
    "\n",
    "        return new_instance\n",
    "\n",
    "    def bootstrap_quantiles(self, quantiles, bootstrap_method='bootstrap'):\n",
    "        \"\"\"\n",
    "        Generate bootstrap quantiles for future time steps.\n",
    "        Args:\n",
    "            quantiles (float or list): Quantiles to be calculated (e.g., 0.1, 0.5, 0.9).\n",
    "            bootstrap_method (str): The method to use for bootstrapping or simulated correlated_forecasts ('bootstrap' or 'correlated').\n",
    "        \"\"\"\n",
    "        ## Make sure bootstrap() method is called before calling this method\n",
    "        if bootstrap_method == 'bootstrap':\n",
    "            if (not hasattr(self, 'bootstrap')):\n",
    "                raise RuntimeError(\"Bootstrap samples not available. Run .bootstrap(df) first.\")\n",
    "            return get_bootstrap_quantiles(self.bootstrap_forecasts, self.n_calib, quantiles, self.y_forecast_b)\n",
    "        elif bootstrap_method == 'correlated':\n",
    "            if (not hasattr(self, 'simulate_correlated_forecasts')):\n",
    "                raise RuntimeError(\"Correlated forecast samples not available. Run .simulate_correlated_forecasts(df) first.\")\n",
    "            return get_bootstrap_quantiles(self.w_samples.T, self.n_calib, quantiles, self.y_forecast_c)\n",
    "    \n",
    "    def simulate_correlated_forecasts(self, df, samples=1000, future_exog=None):\n",
    "        \"\"\"\n",
    "        Simulate correlated errors to generate forecasts\n",
    "        Parameters:\n",
    "        - df: DataFrame containing the training data\n",
    "        - samples: number of samples to generate\n",
    "        - future_exog: optional exogenous variables for forecasting\n",
    "        Returns:\n",
    "        - DataFrame containing the simulated forecasts\n",
    "        \"\"\"\n",
    "        if not hasattr(self, 'resid'):\n",
    "            raise RuntimeError(\"Residuals not available. Run .non_conformity_scores(df) .calibrate(df) or  first.\")\n",
    "        self.model.fit(df, self.n_iter)\n",
    "        if future_exog is not None:\n",
    "            y_forecast = np.array(self.model.forecast(self.H, future_exog))\n",
    "        else:\n",
    "            y_forecast = np.array(self.model.forecast(self.H))\n",
    "\n",
    "        mu = np.mean(self.resid.T, axis=0)\n",
    "        sigma_ = np.cov(self.resid.T, rowvar=False, ddof=1)\n",
    "\n",
    "        rng = np.random.default_rng(seed=42)\n",
    "        samples = rng.multivariate_normal(mu, sigma_, size=samples)\n",
    "        self.w_samples = samples + y_forecast\n",
    "        self.correlated_forecasts = pd.DataFrame(self.w_samples, columns=[f'h_{i+1}' for i in range(self.H)])\n",
    "        self.y_forecast_c = y_forecast\n",
    "        return self\n",
    "\n",
    "class hmm_var_prob_forecasts():\n",
    "    \"\"\"\n",
    "    Probabilistic forecasting for Markov Switching VAR models. It generates prediction intervals for future time steps and approximates distribution of predictions using Kernel Density Estimation (KDE).\n",
    "    Parameters:\n",
    "    - model: forecasting model to be used\n",
    "    - n_calibration: number of calibration windows\n",
    "    - H: forecast horizon\n",
    "    - sliding_window: size of the sliding window for cross-validation\n",
    "    - n_iter: number of iterations for HMM fitting\n",
    "    - verbose: whether to print progress messages\n",
    "    \"\"\"\n",
    "    def __init__(self, model, target_col, n_calibration, H, sliding_window=1, n_iter=1, verbose=False):\n",
    "        self.model = model\n",
    "        self.tar_col = target_col\n",
    "        self.sliding_window = sliding_window\n",
    "        self.n_calib = n_calibration\n",
    "        self.n_iter = n_iter\n",
    "        self.verbose = verbose\n",
    "        self.H = H\n",
    "\n",
    "    def non_conformity_scores(self, df):\n",
    "        c_actuals, c_forecasts = [], []\n",
    "        # Create time series cross-validator that slides 1 time step for each training window\n",
    "        tscv = ParametricTimeSeriesSplit(n_splits=self.n_calib, test_size=self.H, step_size=self.sliding_window)\n",
    "        for train_index, test_index in tscv.split(df):\n",
    "            train, test = df.iloc[train_index], df.iloc[test_index]\n",
    "            x_test = test.drop(columns=self.model.target_col)\n",
    "            y_test = np.array(test[self.tar_col])\n",
    "            self.model.fit(train, self.n_iter)\n",
    "            H_forecasts = self.model.forecast(self.H, x_test)[self.tar_col]\n",
    "            c_forecasts.append(H_forecasts)\n",
    "            c_actuals.append(y_test)\n",
    "            if self.verbose:\n",
    "                print(f\"Completed calibration window {len(c_forecasts)} out of {self.n_calib}\")\n",
    "        self.resid = np.column_stack(c_actuals) - np.column_stack(c_forecasts) # Residuals n_calib*H\n",
    "        self.non_conform = np.abs(self.resid) # non-conformity scores\n",
    "        self.c_actuals = np.column_stack(c_actuals)\n",
    "        self.c_forecasts = np.column_stack(c_forecasts)\n",
    "\n",
    "        \n",
    "    def calculate_quantile(self, scores_calib):\n",
    "        # Vectorized quantile calculation for list delta\n",
    "        if isinstance(self.delta, float):\n",
    "            which_quantile = np.ceil(self.delta * (self.n_calib + 1)) / self.n_calib\n",
    "            return np.quantile(scores_calib, which_quantile, method=\"lower\", axis=0)\n",
    "        elif isinstance(self.delta, list):\n",
    "            which_quantiles = np.ceil(np.array(self.delta) * (self.n_calib + 1)) / self.n_calib\n",
    "            return np.array([np.quantile(scores_calib, q, method=\"lower\", axis=0) for q in which_quantiles])\n",
    "        else:\n",
    "            raise ValueError(\"delta must be float or list of floats.\")\n",
    "    \n",
    "    \n",
    "    def calibrate(self, df, delta = 0.5):\n",
    "        \"\"\"\n",
    "        Calibrate the conformal model using the calibration dataset.\n",
    "        Args:\n",
    "            df (pd.DataFrame): DataFrame containing the calibration data.\n",
    "            delta (float or list): Significance level(s) for the prediction intervals.\n",
    "        \"\"\"\n",
    "        self.delta = delta\n",
    "        self.non_conformity_scores(df=df)\n",
    "        h_quantiles = []\n",
    "        for i in range(self.H):\n",
    "            q_hat = self.calculate_quantile(self.non_conform[i])\n",
    "            h_quantiles.append(q_hat)\n",
    "        self.q_hat_D = np.array(h_quantiles)\n",
    "\n",
    "    # Generate prediction intervals using the calibrated quantiles\n",
    "\n",
    "    def generate_prediction_intervals(self, df, future_exog=None):\n",
    "        '''\n",
    "        Generate conformal prediction intervals for the forecasted values.\n",
    "        Args:\n",
    "            df (pd.DataFrame): DataFrame containing the training data.\n",
    "            future_exog (pd.DataFrame, optional): Future exogenous variables for forecasting.\n",
    "        '''\n",
    "        \n",
    "        if not hasattr(self, 'q_hat_D'):\n",
    "            raise RuntimeError(\"Conformalizer must be calibrated before generating prediction intervals. Run .calibrate(df_calibration) first.\")\n",
    "        self.model.fit(df, self.n_iter)\n",
    "        if future_exog is not None:\n",
    "            y_forecast = np.array(self.model.forecast(self.H, future_exog)[self.tar_col])\n",
    "        else:\n",
    "            y_forecast = np.array(self.model.forecast(self.H)[self.tar_col])\n",
    "        result = [y_forecast]\n",
    "        col_names = [\"point_forecast\"]\n",
    "\n",
    "        if isinstance(self.delta, float):\n",
    "            y_lower, y_upper = y_forecast - self.q_hat_D, y_forecast + self.q_hat_D\n",
    "            result.extend([y_lower, y_upper])\n",
    "            col_names.extend([f'lower_{int(self.delta*100)}', f'upper_{int(self.delta*100)}'])\n",
    "        elif isinstance(self.delta, list):\n",
    "            for idx, d in enumerate(self.delta):\n",
    "                y_lower = y_forecast - self.q_hat_D[:, idx]\n",
    "                y_upper = y_forecast + self.q_hat_D[:, idx]\n",
    "                result.extend([y_lower, y_upper])\n",
    "                col_names.extend([f'lower_{int(d*100)}', f'upper_{int(d*100)}'])\n",
    "        # distributions for each horizons. So add y_forecast array to each columns of self.resid and equal to self.dist\n",
    "        dist = y_forecast[:, None] + self.resid\n",
    "        self.dist = pd.DataFrame(dist.T, columns=[f'h_{i+1}' for i in range(self.H)])\n",
    "        self.dist = self.dist.clip(lower=0.1)\n",
    "        return pd.DataFrame(np.column_stack(result), columns=col_names)\n",
    "\n",
    "    def conformal_quantiles(self, df, quantiles, future_exog=None):\n",
    "        \"\"\"\n",
    "        Generate conformal quantiles for future time steps.\n",
    "        Args:\n",
    "            df (pd.DataFrame): DataFrame containing the training data.\n",
    "            quantiles (float or list): Quantiles to be calculated (e.g., 0.1, 0.5, 0.9).\n",
    "            future_exog (pd.DataFrame, optional): Future exogenous variables for forecasting.\n",
    "        Returns:\n",
    "            pd.DataFrame: DataFrame containing point forecasts and conformal quantiles.\n",
    "        \"\"\"\n",
    "        # Only calibrate if not already done\n",
    "        if not hasattr(self, 'q_hat_D'):\n",
    "            raise RuntimeError(\"Conformalizer must be calibrated before generating prediction intervals. Run .calibrate(df_calibration) first.\")\n",
    "        self.model.fit(df, self.n_iter)\n",
    "        if future_exog is not None:\n",
    "            y_forecast = np.array(self.model.forecast(self.H, future_exog)[self.tar_col])\n",
    "        else:\n",
    "            y_forecast = np.array(self.model.forecast(self.H)[self.tar_col])\n",
    "\n",
    "        return get_conformal_quantiles(self.non_conform, self.n_calib, quantiles, y_forecast)\n",
    "\n",
    "    def bootstrap(self, df, samples=1000, future_exog=None, approximate=\"kde\"):\n",
    "        \"\"\"\n",
    "        Generate samples from the predictive distribution generated by residuals from conformal prediction.\n",
    "        The samples are drawn from a Gaussian kernel density estimate of the residuals.\n",
    "        \"\"\"\n",
    "        # Return a random sample from Gaussian Kernel density estimation\n",
    "        if not hasattr(self, 'resid'):\n",
    "            raise RuntimeError(\"Residuals not available. Run .non_conformity_scores(df) .calibrate(df) or  first.\")\n",
    "        self.model.fit(df, self.n_iter)\n",
    "        if future_exog is not None:\n",
    "            y_forecast = np.array(self.model.forecast(self.H, future_exog)[self.tar_col])\n",
    "        else:\n",
    "            y_forecast = np.array(self.model.forecast(self.H)[self.tar_col])\n",
    "\n",
    "        # ✅ Create a deep copy so that we don’t overwrite self\n",
    "        new_instance = copy.deepcopy(self)\n",
    "        if approximate == \"kde\":\n",
    "            new_instance.bootstrap_forecasts = np.column_stack([[gaussian_kde(new_instance.resid[i]).resample(size=samples, seed=rng_kde)+y_forecast[i]]\n",
    "                                        for i in range(new_instance.H)])[0] # H x samples\n",
    "        elif approximate == \"empirical\":\n",
    "            new_instance.bootstrap_forecasts = np.column_stack([np.random.choice(new_instance.resid[i], size=samples, replace=True)+y_forecast[i]\n",
    "                for i in range(self.H)]).T\n",
    "        else:\n",
    "            raise ValueError(\"approximate must be 'kde' or 'empirical'.\")\n",
    "\n",
    "        new_instance.bootstrap_forecasts_df = pd.DataFrame(new_instance.bootstrap_forecasts.T, columns=[f'h_{i+1}' for i in range(self.H)])\n",
    "        new_instance.y_forecast_b = y_forecast\n",
    "\n",
    "        return new_instance\n",
    "\n",
    "    def bootstrap_quantiles(self, quantiles, bootstrap_method='bootstrap'):\n",
    "        \"\"\"\n",
    "        Generate bootstrap quantiles for future time steps.\n",
    "        Args:\n",
    "            quantiles (float or list): Quantiles to be calculated (e.g., 0.1, 0.5, 0.9).\n",
    "            bootstrap_method (str): The method to use for bootstrapping or simulated correlated_forecasts ('bootstrap' or 'correlated').\n",
    "        \"\"\"\n",
    "        ## Make sure bootstrap() method is called before calling this method\n",
    "        if bootstrap_method == 'bootstrap':\n",
    "            if (not hasattr(self, 'bootstrap')):\n",
    "                raise RuntimeError(\"Bootstrap samples not available. Run .bootstrap(df) first.\")\n",
    "            return get_bootstrap_quantiles(self.bootstrap_forecasts, self.n_calib, quantiles, self.y_forecast_b)\n",
    "        elif bootstrap_method == 'correlated':\n",
    "            if (not hasattr(self, 'simulate_correlated_forecasts')):\n",
    "                raise RuntimeError(\"Correlated forecast samples not available. Run .simulate_correlated_forecasts(df) first.\")\n",
    "            return get_bootstrap_quantiles(self.w_samples.T, self.n_calib, quantiles, self.y_forecast_c)\n",
    "    \n",
    "    def simulate_correlated_forecasts(self, df, samples=1000, future_exog=None):\n",
    "        \"\"\"\n",
    "        Simulate correlated errors to generate forecasts\n",
    "        Parameters:\n",
    "        - df: DataFrame containing the training data\n",
    "        - samples: number of samples to generate\n",
    "        - future_exog: optional exogenous variables for forecasting\n",
    "        Returns:\n",
    "        - DataFrame containing the simulated forecasts\n",
    "        \"\"\"\n",
    "        if not hasattr(self, 'resid'):\n",
    "            raise RuntimeError(\"Residuals not available. Run .non_conformity_scores(df) .calibrate(df) or  first.\")\n",
    "        self.model.fit(df, self.n_iter)\n",
    "        if future_exog is not None:\n",
    "            y_forecast = np.array(self.model.forecast(self.H, future_exog)[self.tar_col])\n",
    "        else:\n",
    "            y_forecast = np.array(self.model.forecast(self.H)[self.tar_col])\n",
    "\n",
    "        mu = np.mean(self.resid.T, axis=0)\n",
    "        sigma_ = np.cov(self.resid.T, rowvar=False, ddof=1)\n",
    "        rng = np.random.default_rng(seed=42)\n",
    "        samples = rng.multivariate_normal(mu, sigma_, size=samples)\n",
    "        self.w_samples = samples + y_forecast\n",
    "        self.correlated_forecasts = pd.DataFrame(self.w_samples, columns=[f'h_{i+1}' for i in range(self.H)])\n",
    "        self.y_forecast_c = y_forecast\n",
    "        return self\n",
    "\n",
    "class ets_prob_forecasts():\n",
    "    \"\"\"\n",
    "    Probabilistic forecasting for Exponential Smoothing State Space Model (ETS). It generates prediction intervals for future time steps and approximates distribution of predictions using Kernel Density Estimation (KDE).\n",
    "    Parameters:\n",
    "    - ets_param: parameters for ETS model. A tuble of (dict, dict) where first dict is for ExponentialSmoothing() and second dict is for .fit()\n",
    "    - n_calibration: number of calibration windows\n",
    "    - H: forecast horizon\n",
    "    - sliding_window: size of the sliding window for cross-validation\n",
    "    - verbose: whether to print progress messages\n",
    "    \"\"\"\n",
    "    def __init__(self, ets_param, n_calibration,\n",
    "                 H, sliding_window=1, verbose=False):\n",
    "        self.ets_param = ets_param\n",
    "        self.sliding_window = sliding_window\n",
    "        self.n_calib = n_calibration\n",
    "        self.verbose = verbose\n",
    "        self.H = H\n",
    "\n",
    "    def non_conformity_scores(self, series):\n",
    "        c_actuals, c_forecasts = [], []\n",
    "        # Create time series cross-validator that slides 1 time step for each training window\n",
    "        tscv = ParametricTimeSeriesSplit(n_splits=self.n_calib, test_size=self.H, step_size=self.sliding_window)\n",
    "\n",
    "        for train_index, test_index in tscv.split(series):\n",
    "            train, test = series[train_index], series[test_index]\n",
    "            y_test = np.array(test)\n",
    "            self.model = ExponentialSmoothing(train,\n",
    "                            **self.ets_param[0]).fit(**self.ets_param[1])\n",
    "            H_forecasts = np.array(self.model.forecast(self.H))\n",
    "            c_forecasts.append(H_forecasts)\n",
    "            c_actuals.append(y_test)\n",
    "            if self.verbose:\n",
    "                print(f\"Completed calibration window {len(c_forecasts)} out of {self.n_calib}\")\n",
    "        self.resid = np.column_stack(c_actuals) - np.column_stack(c_forecasts) # Residuals n_calib*H\n",
    "        self.non_conform = np.abs(self.resid) # non-conformity scores\n",
    "        self.c_actuals = np.column_stack(c_actuals)\n",
    "        self.c_forecasts = np.column_stack(c_forecasts)\n",
    "\n",
    "    def calculate_quantile(self, scores_calib):\n",
    "        # Vectorized quantile calculation for list delta\n",
    "        if isinstance(self.delta, float):\n",
    "            which_quantile = np.ceil(self.delta * (self.n_calib + 1)) / self.n_calib\n",
    "            return np.quantile(scores_calib, which_quantile, method=\"lower\", axis=0)\n",
    "        elif isinstance(self.delta, list):\n",
    "            which_quantiles = np.ceil(np.array(self.delta) * (self.n_calib + 1)) / self.n_calib\n",
    "            return np.array([np.quantile(scores_calib, q, method=\"lower\", axis=0) for q in which_quantiles])\n",
    "        else:\n",
    "            raise ValueError(\"delta must be float or list of floats.\")\n",
    "    \n",
    "    def calibrate(self, series, delta = 0.5):\n",
    "        \"\"\"\n",
    "        Calibrate the conformal model using the calibration dataset.\n",
    "        Args:\n",
    "            series: pd.Series or np.array containing the calibration data.\n",
    "            delta (float or list): Significance level(s) for the prediction intervals.\n",
    "        \"\"\"\n",
    "        self.delta = delta\n",
    "        self.non_conformity_scores(series)\n",
    "        h_quantiles = []\n",
    "        for i in range(self.H):\n",
    "            q_hat = self.calculate_quantile(self.non_conform[i])\n",
    "            h_quantiles.append(q_hat)\n",
    "        self.q_hat_D = np.array(h_quantiles)\n",
    "\n",
    "    # Generate prediction intervals using the calibrated quantiles\n",
    "\n",
    "    def generate_prediction_intervals(self, series):\n",
    "        '''\n",
    "        Generate conformal prediction intervals for the forecasted values.\n",
    "        Args:\n",
    "            series: pd.Series or np.array containing the training data.\n",
    "        '''\n",
    "        if not hasattr(self, 'q_hat_D'):\n",
    "            raise RuntimeError(\"Conformalizer must be calibrated before generating prediction intervals. Run .calibrate(df_calibration) first.\")\n",
    "        self.model = ExponentialSmoothing(series,\n",
    "                            **self.ets_param[0]).fit(**self.ets_param[1])\n",
    "        y_forecast = np.array(self.model.forecast(self.H))\n",
    "        result = [y_forecast]\n",
    "        col_names = [\"point_forecast\"]\n",
    "\n",
    "        if isinstance(self.delta, float):\n",
    "            y_lower, y_upper = y_forecast - self.q_hat_D, y_forecast + self.q_hat_D\n",
    "            result.extend([y_lower, y_upper])\n",
    "            col_names.extend([f'lower_{int(self.delta*100)}', f'upper_{int(self.delta*100)}'])\n",
    "        elif isinstance(self.delta, list):\n",
    "            for idx, d in enumerate(self.delta):\n",
    "                y_lower = y_forecast - self.q_hat_D[:, idx]\n",
    "                y_upper = y_forecast + self.q_hat_D[:, idx]\n",
    "                result.extend([y_lower, y_upper])\n",
    "                col_names.extend([f'lower_{int(d*100)}', f'upper_{int(d*100)}'])\n",
    "        # distributions for each horizons. So add y_forecast array to each columns of self.resid and equal to self.dist\n",
    "        dist = y_forecast[:, None] + self.resid\n",
    "        self.dist = pd.DataFrame(dist.T, columns=[f'h_{i+1}' for i in range(self.H)])\n",
    "        self.dist = self.dist.clip(lower=0.1)\n",
    "        return pd.DataFrame(np.column_stack(result), columns=col_names)\n",
    "\n",
    "    def conformal_quantiles(self, series, quantiles):\n",
    "        \"\"\"\n",
    "        Generate conformal quantiles for future time steps.\n",
    "        Args:\n",
    "            series: pd.Series or np.array containing the training data.\n",
    "            quantiles (float or list): Quantiles to be calculated (e.g., 0.1, 0.5, 0.9).\n",
    "            future_exog (pd.DataFrame, optional): Future exogenous variables for forecasting.\n",
    "        Returns:\n",
    "            pd.DataFrame: DataFrame containing point forecasts and conformal quantiles.\n",
    "        \"\"\"\n",
    "        if not hasattr(self, 'q_hat_D'):\n",
    "            raise RuntimeError(\"Conformalizer must be calibrated before generating prediction intervals. Run .calibrate(df_calibration) first.\")\n",
    "        self.model = ExponentialSmoothing(series,\n",
    "                            **self.ets_param[0]).fit(**self.ets_param[1])\n",
    "        y_forecast = np.array(self.model.forecast(self.H))\n",
    "\n",
    "        return get_conformal_quantiles(self.non_conform, self.n_calib, quantiles, y_forecast)\n",
    "\n",
    "    def bootstrap(self, series, samples=1000, approximate=\"kde\"):\n",
    "        \"\"\"\n",
    "        Generate samples from the predictive distribution generated by residuals from conformal prediction.\n",
    "        The samples are drawn from a Gaussian kernel density estimate of the residuals.\n",
    "        \"\"\"\n",
    "        # Return a random sample from Gaussian Kernel density estimation\n",
    "        if not hasattr(self, 'resid'):\n",
    "            raise RuntimeError(\"Residuals not available. Run .non_conformity_scores(df) .calibrate(df) or  first.\")\n",
    "\n",
    "        self.model = ExponentialSmoothing(series,\n",
    "                            **self.ets_param[0]).fit(**self.ets_param[1])\n",
    "        y_forecast = np.array(self.model.forecast(self.H))\n",
    "\n",
    "        # ✅ Create a deep copy so that we don’t overwrite self\n",
    "        new_instance = copy.deepcopy(self)\n",
    "        if approximate == \"kde\":\n",
    "            new_instance.bootstrap_forecasts = np.column_stack([[gaussian_kde(new_instance.resid[i]).resample(size=samples, seed=rng_kde)+y_forecast[i]]\n",
    "                                        for i in range(new_instance.H)])[0] # H x samples\n",
    "        elif approximate == \"empirical\":\n",
    "            new_instance.bootstrap_forecasts = np.column_stack([np.random.choice(new_instance.resid[i], size=samples, replace=True)+y_forecast[i]\n",
    "                for i in range(self.H)]).T\n",
    "        else:\n",
    "            raise ValueError(\"approximate must be 'kde' or 'empirical'.\")\n",
    "\n",
    "        new_instance.bootstrap_forecasts_df = pd.DataFrame(new_instance.bootstrap_forecasts.T, columns=[f'h_{i+1}' for i in range(self.H)])\n",
    "        new_instance.y_forecast_b = y_forecast\n",
    "\n",
    "        return new_instance\n",
    "\n",
    "    def bootstrap_quantiles(self, quantiles, bootstrap_method='bootstrap'):\n",
    "        \"\"\"\n",
    "        Generate bootstrap quantiles for future time steps.\n",
    "        Args:\n",
    "            quantiles (float or list): Quantiles to be calculated (e.g., 0.1, 0.5, 0.9).\n",
    "            bootstrap_method (str): The method to use for bootstrapping or simulated correlated_forecasts ('bootstrap' or 'correlated').\n",
    "        \"\"\"\n",
    "        ## Make sure bootstrap() method is called before calling this method\n",
    "        if bootstrap_method == 'bootstrap':\n",
    "            if (not hasattr(self, 'bootstrap')):\n",
    "                raise RuntimeError(\"Bootstrap samples not available. Run .bootstrap(df) first.\")\n",
    "            return get_bootstrap_quantiles(self.bootstrap_forecasts, self.n_calib, quantiles, self.y_forecast_b)\n",
    "        elif bootstrap_method == 'correlated':\n",
    "            if (not hasattr(self, 'simulate_correlated_forecasts')):\n",
    "                raise RuntimeError(\"Correlated forecast samples not available. Run .simulate_correlated_forecasts(df) first.\")\n",
    "            return get_bootstrap_quantiles(self.w_samples.T, self.n_calib, quantiles, self.y_forecast_c)\n",
    "\n",
    "    def simulate_correlated_forecasts(self, series, samples=1000):\n",
    "        \"\"\"\n",
    "        Simulate correlated errors to generate forecasts\n",
    "        Parameters:\n",
    "        - df: DataFrame containing the training data\n",
    "        - samples: number of samples to generate\n",
    "        - future_exog: optional exogenous variables for forecasting\n",
    "        Returns:\n",
    "        - DataFrame containing the simulated forecasts\n",
    "        \"\"\"\n",
    "        if not hasattr(self, 'resid'):\n",
    "            raise RuntimeError(\"Residuals not available. Run .non_conformity_scores(df) .calibrate(df) or  first.\")\n",
    "\n",
    "        self.model = ExponentialSmoothing(series,\n",
    "                            **self.ets_param[0]).fit(**self.ets_param[1])\n",
    "        y_forecast = np.array(self.model.forecast(self.H))\n",
    "\n",
    "        mu = np.mean(self.resid.T, axis=0)\n",
    "        sigma_ = np.cov(self.resid.T, rowvar=False, ddof=1)\n",
    "\n",
    "        rng = np.random.default_rng(seed=42)\n",
    "        samples = rng.multivariate_normal(mu, sigma_, size=samples)\n",
    "        self.w_samples = samples + y_forecast\n",
    "        self.correlated_forecasts = pd.DataFrame(self.w_samples, columns=[f'h_{i+1}' for i in range(self.H)])\n",
    "        self.y_forecast_c = y_forecast\n",
    "        return self\n",
    "    \n",
    "class naive_prob_forecasts():\n",
    "    \"\"\"\n",
    "    Probabilistic forecasting for Naive forecasting model. It generates prediction intervals for future time steps and approximates distribution of predictions using Kernel Density Estimation (KDE).\n",
    "    - n_calibration: number of calibration windows\n",
    "    - H: forecast horizon\n",
    "    - sliding_window: size of the sliding window for cross-validation\n",
    "    - season_period: seasonal period for naive forecasting\n",
    "    - verbose: whether to print progress messages\n",
    "    \"\"\"\n",
    "    def __init__(self, n_calibration,\n",
    "                 H, sliding_window=1, season_period=None, verbose=False):\n",
    "        self.sliding_window = sliding_window\n",
    "        self.n_calib = n_calibration\n",
    "        self.verbose = verbose\n",
    "        self.H = H\n",
    "        self.season_period = season_period\n",
    "\n",
    "    def naive(self, series, H, season_period=None):\n",
    "        \"\"\"Generate naive forecasts.\n",
    "\n",
    "        Parameters:\n",
    "        series (pd.Series): Time series data.\n",
    "        H (int): Forecast horizon.\n",
    "        season_period (int, optional): Seasonal period. If None, non-seasonal naive is used.\n",
    "        Returns:\n",
    "        np.ndarray: Forecasted values for the next H periods.\n",
    "        \"\"\"\n",
    "        s = series.dropna()\n",
    "        if season_period is None:\n",
    "            # Non-seasonal naive: repeat last observed value H times\n",
    "            if len(s) == 0:\n",
    "                y_forecast = np.full(H, np.nan)\n",
    "            else:\n",
    "                last_val = s.iloc[-1]\n",
    "                y_forecast = np.full(H, last_val)\n",
    "        else:\n",
    "            # Seasonal naive: use values from one season back, repeated/cycled\n",
    "            if len(s) < season_period:\n",
    "                y_forecast = np.full(H, np.nan)\n",
    "            else:\n",
    "                last_season = s.iloc[-season_period:]\n",
    "                repeats = H // season_period\n",
    "                remainder = H % season_period\n",
    "                y_forecast = np.tile(last_season.values, repeats)\n",
    "                if remainder > 0:\n",
    "                    y_forecast = np.concatenate([y_forecast, last_season.values[:remainder]])\n",
    "        return y_forecast\n",
    "\n",
    "\n",
    "    def non_conformity_scores(self, series):\n",
    "        c_actuals, c_forecasts = [], []\n",
    "        # Create time series cross-validator that slides 1 time step for each training window\n",
    "        tscv = ParametricTimeSeriesSplit(n_splits=self.n_calib, test_size=self.H, step_size=self.sliding_window)\n",
    "\n",
    "        for train_index, test_index in tscv.split(series):\n",
    "            train, test = series[train_index], series[test_index]\n",
    "            y_test = np.array(test)\n",
    "            H_forecasts = np.array(self.naive(train, self.H, season_period=self.season_period))\n",
    "            c_forecasts.append(H_forecasts)\n",
    "            c_actuals.append(y_test)\n",
    "            if self.verbose:\n",
    "                print(f\"Completed calibration window {len(c_forecasts)} out of {self.n_calib}\")\n",
    "        self.resid = np.column_stack(c_actuals) - np.column_stack(c_forecasts) # Residuals n_calib*H\n",
    "        self.non_conform = np.abs(self.resid) # non-conformity scores\n",
    "        self.c_actuals = np.column_stack(c_actuals)\n",
    "        self.c_forecasts = np.column_stack(c_forecasts)\n",
    "\n",
    "    def calculate_quantile(self, scores_calib):\n",
    "        # Vectorized quantile calculation for list delta\n",
    "        if isinstance(self.delta, float):\n",
    "            which_quantile = np.ceil(self.delta * (self.n_calib + 1)) / self.n_calib\n",
    "            return np.quantile(scores_calib, which_quantile, method=\"lower\", axis=0)\n",
    "        elif isinstance(self.delta, list):\n",
    "            which_quantiles = np.ceil(np.array(self.delta) * (self.n_calib + 1)) / self.n_calib\n",
    "            return np.array([np.quantile(scores_calib, q, method=\"lower\", axis=0) for q in which_quantiles])\n",
    "        else:\n",
    "            raise ValueError(\"delta must be float or list of floats.\")\n",
    "    \n",
    "    def calibrate(self, series, delta = 0.5):\n",
    "        \"\"\"\n",
    "        Calibrate the conformal model using the calibration dataset.\n",
    "        Args:\n",
    "            series: pd.Series or np.array containing the calibration data.\n",
    "            delta (float or list): Significance level(s) for the prediction intervals.\n",
    "        \"\"\"\n",
    "        self.delta = delta\n",
    "        self.non_conformity_scores(series)\n",
    "        h_quantiles = []\n",
    "        for i in range(self.H):\n",
    "            q_hat = self.calculate_quantile(self.non_conform[i])\n",
    "            h_quantiles.append(q_hat)\n",
    "        self.q_hat_D = np.array(h_quantiles)\n",
    "\n",
    "    # Generate prediction intervals using the calibrated quantiles\n",
    "\n",
    "    def generate_prediction_intervals(self, series):\n",
    "        '''\n",
    "        Generate conformal prediction intervals for the forecasted values.\n",
    "        Args:\n",
    "            series: pd.Series or np.array containing the training data.\n",
    "        '''\n",
    "        if not hasattr(self, 'q_hat_D'):\n",
    "            raise RuntimeError(\"Conformalizer must be calibrated before generating prediction intervals. Run .calibrate(df_calibration) first.\")\n",
    "    \n",
    "        y_forecast = np.array(self.naive(series, self.H, season_period=self.season_period))\n",
    "        result = [y_forecast]\n",
    "        col_names = [\"point_forecast\"]\n",
    "\n",
    "        if isinstance(self.delta, float):\n",
    "            y_lower, y_upper = y_forecast - self.q_hat_D, y_forecast + self.q_hat_D\n",
    "            result.extend([y_lower, y_upper])\n",
    "            col_names.extend([f'lower_{int(self.delta*100)}', f'upper_{int(self.delta*100)}'])\n",
    "        elif isinstance(self.delta, list):\n",
    "            for idx, d in enumerate(self.delta):\n",
    "                y_lower = y_forecast - self.q_hat_D[:, idx]\n",
    "                y_upper = y_forecast + self.q_hat_D[:, idx]\n",
    "                result.extend([y_lower, y_upper])\n",
    "                col_names.extend([f'lower_{int(d*100)}', f'upper_{int(d*100)}'])\n",
    "        # distributions for each horizons. So add y_forecast array to each columns of self.resid and equal to self.dist\n",
    "        dist = y_forecast[:, None] + self.resid\n",
    "        self.dist = pd.DataFrame(dist.T, columns=[f'h_{i+1}' for i in range(self.H)])\n",
    "        self.dist = self.dist.clip(lower=0.1)\n",
    "        return pd.DataFrame(np.column_stack(result), columns=col_names)\n",
    "\n",
    "    def conformal_quantiles(self, series, quantiles):\n",
    "        \"\"\"\n",
    "        Generate conformal quantiles for future time steps.\n",
    "        Args:\n",
    "            series: pd.Series or np.array containing the training data.\n",
    "            quantiles (float or list): Quantiles to be calculated (e.g., 0.1, 0.5, 0.9).\n",
    "            future_exog (pd.DataFrame, optional): Future exogenous variables for forecasting.\n",
    "        Returns:\n",
    "            pd.DataFrame: DataFrame containing point forecasts and conformal quantiles.\n",
    "        \"\"\"\n",
    "        if not hasattr(self, 'q_hat_D'):\n",
    "            raise RuntimeError(\"Conformalizer must be calibrated before generating prediction intervals. Run .calibrate(df_calibration) first.\")\n",
    "\n",
    "        y_forecast = np.array(self.naive(series, self.H, season_period=self.season_period))\n",
    "\n",
    "        return get_conformal_quantiles(self.non_conform, self.n_calib, quantiles, y_forecast)\n",
    "\n",
    "    def bootstrap(self, series, samples=1000, approximate=\"kde\"):\n",
    "        \"\"\"\n",
    "        Generate samples from the predictive distribution generated by residuals from conformal prediction.\n",
    "        The samples are drawn from a Gaussian kernel density estimate of the residuals.\n",
    "        \"\"\"\n",
    "        # Return a random sample from Gaussian Kernel density estimation\n",
    "        if not hasattr(self, 'resid'):\n",
    "            raise RuntimeError(\"Residuals not available. Run .non_conformity_scores(df) .calibrate(df) or  first.\")\n",
    "\n",
    "        y_forecast = np.array(self.naive(series, self.H, season_period=self.season_period))\n",
    "\n",
    "        # ✅ Create a deep copy so that we don’t overwrite self\n",
    "        new_instance = copy.deepcopy(self)\n",
    "        if approximate == \"kde\":\n",
    "            new_instance.bootstrap_forecasts = np.column_stack([[gaussian_kde(new_instance.resid[i]).resample(size=samples, seed=rng_kde)+y_forecast[i]]\n",
    "                                        for i in range(new_instance.H)])[0] # H x samples\n",
    "        elif approximate == \"empirical\":\n",
    "            new_instance.bootstrap_forecasts = np.column_stack([np.random.choice(new_instance.resid[i], size=samples, replace=True)+y_forecast[i]\n",
    "                for i in range(self.H)]).T\n",
    "        else:\n",
    "            raise ValueError(\"approximate must be 'kde' or 'empirical'.\")\n",
    "\n",
    "        new_instance.bootstrap_forecasts_df = pd.DataFrame(new_instance.bootstrap_forecasts.T, columns=[f'h_{i+1}' for i in range(self.H)])\n",
    "        new_instance.y_forecast_b = y_forecast\n",
    "\n",
    "        return new_instance\n",
    "\n",
    "    def bootstrap_quantiles(self, quantiles, bootstrap_method='bootstrap'):\n",
    "        \"\"\"\n",
    "        Generate bootstrap quantiles for future time steps.\n",
    "        Args:\n",
    "            quantiles (float or list): Quantiles to be calculated (e.g., 0.1, 0.5, 0.9).\n",
    "            bootstrap_method (str): The method to use for bootstrapping or simulated correlated_forecasts ('bootstrap' or 'correlated').\n",
    "        \"\"\"\n",
    "        ## Make sure bootstrap() method is called before calling this method\n",
    "        if bootstrap_method == 'bootstrap':\n",
    "            if (not hasattr(self, 'bootstrap')):\n",
    "                raise RuntimeError(\"Bootstrap samples not available. Run .bootstrap(df) first.\")\n",
    "            return get_bootstrap_quantiles(self.bootstrap_forecasts, self.n_calib, quantiles, self.y_forecast_b)\n",
    "        elif bootstrap_method == 'correlated':\n",
    "            if (not hasattr(self, 'simulate_correlated_forecasts')):\n",
    "                raise RuntimeError(\"Correlated forecast samples not available. Run .simulate_correlated_forecasts(df) first.\")\n",
    "            return get_bootstrap_quantiles(self.w_samples.T, self.n_calib, quantiles, self.y_forecast_c)\n",
    "\n",
    "    def simulate_correlated_forecasts(self, series, samples=1000):\n",
    "        \"\"\"\n",
    "        Simulate correlated errors to generate forecasts\n",
    "        Parameters:\n",
    "        - df: DataFrame containing the training data\n",
    "        - samples: number of samples to generate\n",
    "        - future_exog: optional exogenous variables for forecasting\n",
    "        Returns:\n",
    "        - DataFrame containing the simulated forecasts\n",
    "        \"\"\"\n",
    "        if not hasattr(self, 'resid'):\n",
    "            raise RuntimeError(\"Residuals not available. Run .non_conformity_scores(df) .calibrate(df) or  first.\")\n",
    "\n",
    "        y_forecast = np.array(self.naive(series, self.H, season_period=self.season_period))\n",
    "\n",
    "        mu = np.mean(self.resid.T, axis=0)\n",
    "        sigma_ = np.cov(self.resid.T, rowvar=False, ddof=1)\n",
    "\n",
    "        rng = np.random.default_rng(seed=42)\n",
    "        samples = rng.multivariate_normal(mu, sigma_, size=samples)\n",
    "        self.w_samples = samples + y_forecast\n",
    "        self.correlated_forecasts = pd.DataFrame(self.w_samples, columns=[f'h_{i+1}' for i in range(self.H)])\n",
    "        self.y_forecast_c = y_forecast\n",
    "        return self\n",
    "    \n",
    "class arima_prob_forecasts():\n",
    "    \"\"\"\n",
    "    Probabilistic forecasting for ARIMA model. It generates prediction intervals for future time steps and approximates distribution of predictions using Kernel Density Estimation (KDE).\n",
    "    Parameters:\n",
    "    - model: ARIMA model instance supported by statsforecast (Nixtla)\n",
    "    - n_calibration: number of calibration windows\n",
    "    - H: forecast horizon\n",
    "    - sliding_window: size of the sliding window for cross-validation\n",
    "    - verbose: whether to print progress messages\n",
    "    \"\"\"\n",
    "    def __init__(self, model, n_calibration, H, sliding_window=1, verbose=False):\n",
    "        self.model = model\n",
    "        self.sliding_window = sliding_window\n",
    "        self.n_calib = n_calibration\n",
    "        self.verbose = verbose\n",
    "        self.H = H\n",
    "\n",
    "    def non_conformity_scores(self, df):\n",
    "        c_actuals, c_forecasts = [], []\n",
    "        # Create time series cross-validator that slides 1 time step for each training window\n",
    "        tscv = ParametricTimeSeriesSplit(n_splits=self.n_calib, test_size=self.H, step_size=self.sliding_window)\n",
    "        for train_index, test_index in tscv.split(df):\n",
    "            train, test = df.iloc[train_index], df.iloc[test_index]\n",
    "            y_test = np.array(test[self.target_col])\n",
    "            H_forecasts = self.model.forecast(y=np.array(train[self.target_col]), h=self.H, X=np.array(train.drop(columns=[self.target_col])),\n",
    "                                X_future=np.array(test.drop(columns=[self.target_col])))[\"mean\"]\n",
    "            c_forecasts.append(H_forecasts)\n",
    "            c_actuals.append(y_test)\n",
    "            if self.verbose:\n",
    "                print(f\"Completed calibration window {len(c_forecasts)} out of {self.n_calib}\")\n",
    "        self.resid = np.column_stack(c_actuals) - np.column_stack(c_forecasts) # Residuals n_calib*H\n",
    "        self.non_conform = np.abs(self.resid) # non-conformity scores\n",
    "        self.c_actuals = np.column_stack(c_actuals)\n",
    "        self.c_forecasts = np.column_stack(c_forecasts)\n",
    "\n",
    "        \n",
    "    def calculate_quantile(self, scores_calib):\n",
    "        # Vectorized quantile calculation for list delta\n",
    "        if isinstance(self.delta, float):\n",
    "            which_quantile = np.ceil(self.delta * (self.n_calib + 1)) / self.n_calib\n",
    "            return np.quantile(scores_calib, which_quantile, method=\"lower\", axis=0)\n",
    "        elif isinstance(self.delta, list):\n",
    "            which_quantiles = np.ceil(np.array(self.delta) * (self.n_calib + 1)) / self.n_calib\n",
    "            return np.array([np.quantile(scores_calib, q, method=\"lower\", axis=0) for q in which_quantiles])\n",
    "        else:\n",
    "            raise ValueError(\"delta must be float or list of floats.\")\n",
    "    \n",
    "    def calibrate(self, df, target_col, delta = 0.5):\n",
    "        \"\"\"\n",
    "        Calibrate the conformal model using the calibration dataset.\n",
    "        Args:\n",
    "            df (pd.DataFrame): DataFrame containing the calibration data.\n",
    "            target_col (str): Name of the target column in the DataFrame.\n",
    "            delta (float or list): Significance level(s) for the prediction intervals.\n",
    "        \"\"\"\n",
    "        self.delta = delta\n",
    "        self.target_col = target_col\n",
    "        self.non_conformity_scores(df=df)\n",
    "        h_quantiles = []\n",
    "        for i in range(self.H):\n",
    "            q_hat = self.calculate_quantile(self.non_conform[i])\n",
    "            h_quantiles.append(q_hat)\n",
    "        self.q_hat_D = np.array(h_quantiles)\n",
    "\n",
    "    # Generate prediction intervals using the calibrated quantiles\n",
    "\n",
    "    def generate_prediction_intervals(self, df, future_exog=None):\n",
    "        '''\n",
    "        Generate conformal prediction intervals for the forecasted values.\n",
    "        Args:\n",
    "            df (pd.DataFrame): DataFrame containing the training data.\n",
    "            future_exog (pd.DataFrame, optional): Future exogenous variables for forecasting.\n",
    "        '''\n",
    "        if not hasattr(self, 'q_hat_D'):\n",
    "            raise RuntimeError(\"Conformalizer must be calibrated before generating prediction intervals. Run .calibrate(df_calibration) first.\")\n",
    "        y_train = df[self.target_col]\n",
    "        x_train = df.drop(columns=[self.target_col])\n",
    "        if future_exog is not None:\n",
    "            y_forecast = self.model.forecast(y=np.array(y_train), h=self.H, X=np.array(x_train),\n",
    "                    X_future=np.array(future_exog))[\"mean\"]\n",
    "        else:\n",
    "            y_forecast = self.model.forecast(y=np.array(y_train), h=self.H, X=np.array(x_train))[\"mean\"]\n",
    "        result = [y_forecast]\n",
    "        col_names = [\"point_forecast\"]\n",
    "\n",
    "        if isinstance(self.delta, float):\n",
    "            y_lower, y_upper = y_forecast - self.q_hat_D, y_forecast + self.q_hat_D\n",
    "            result.extend([y_lower, y_upper])\n",
    "            col_names.extend([f'lower_{int(self.delta*100)}', f'upper_{int(self.delta*100)}'])\n",
    "        elif isinstance(self.delta, list):\n",
    "            for idx, d in enumerate(self.delta):\n",
    "                y_lower = y_forecast - self.q_hat_D[:, idx]\n",
    "                y_upper = y_forecast + self.q_hat_D[:, idx]\n",
    "                result.extend([y_lower, y_upper])\n",
    "                col_names.extend([f'lower_{int(d*100)}', f'upper_{int(d*100)}'])\n",
    "        # distributions for each horizons. So add y_forecast array to each columns of self.resid and equal to self.dist\n",
    "        dist = y_forecast[:, None] + self.resid\n",
    "        self.dist = pd.DataFrame(dist.T, columns=[f'h_{i+1}' for i in range(self.H)])\n",
    "        self.dist = self.dist.clip(lower=0.1)\n",
    "        return pd.DataFrame(np.column_stack(result), columns=col_names)\n",
    "\n",
    "    def conformal_quantiles(self, df, quantiles, future_exog=None):\n",
    "        \"\"\"\n",
    "        Generate conformal quantiles for future time steps.\n",
    "        Args:\n",
    "            df (pd.DataFrame): DataFrame containing the training data.\n",
    "            quantiles (float or list): Quantiles to be calculated (e.g., 0.1, 0.5, 0.9).\n",
    "            future_exog (pd.DataFrame, optional): Future exogenous variables for forecasting.\n",
    "        Returns:\n",
    "            pd.DataFrame: DataFrame containing point forecasts and conformal quantiles.\n",
    "        \"\"\"\n",
    "        # Only calibrate if not already done\n",
    "        if not hasattr(self, 'q_hat_D'):\n",
    "            raise RuntimeError(\"Conformalizer must be calibrated before generating prediction intervals. Run .calibrate(df_calibration) first.\")\n",
    "        y_train = df[self.target_col]\n",
    "        x_train = df.drop(columns=[self.target_col])\n",
    "        if future_exog is not None:\n",
    "            y_forecast = self.model.forecast(y=np.array(y_train), h=self.H, X=np.array(x_train),\n",
    "                    X_future=np.array(future_exog))[\"mean\"]\n",
    "        else:\n",
    "            y_forecast = self.model.forecast(y=np.array(y_train), h=self.H, X=np.array(x_train))[\"mean\"]\n",
    "\n",
    "        return get_conformal_quantiles(self.non_conform, self.n_calib, quantiles, y_forecast)\n",
    "\n",
    "    def bootstrap(self, df, samples=1000, future_exog=None, approximate=\"kde\"):\n",
    "        \"\"\"\n",
    "        Generate samples from the predictive distribution generated by residuals from conformal prediction.\n",
    "        The samples are drawn from a Gaussian kernel density estimate of the residuals.\n",
    "        \"\"\"\n",
    "        # Return a random sample from Gaussian Kernel density estimation\n",
    "        if not hasattr(self, 'resid'):\n",
    "            raise RuntimeError(\"Residuals not available. Run .non_conformity_scores(df) .calibrate(df) or  first.\")\n",
    "        y_train = df[self.target_col]\n",
    "        x_train = df.drop(columns=[self.target_col])\n",
    "        if future_exog is not None:\n",
    "            y_forecast = self.model.forecast(y=np.array(y_train), h=self.H, X=np.array(x_train),\n",
    "                    X_future=np.array(future_exog))[\"mean\"]\n",
    "        else:\n",
    "            y_forecast = self.model.forecast(y=np.array(y_train), h=self.H, X=np.array(x_train))[\"mean\"]\n",
    "\n",
    "        # ✅ Create a deep copy so that we don’t overwrite self\n",
    "        new_instance = copy.deepcopy(self)\n",
    "        if approximate == \"kde\":\n",
    "            new_instance.bootstrap_forecasts = np.column_stack([[gaussian_kde(new_instance.resid[i]).resample(size=samples, seed=rng_kde)+y_forecast[i]]\n",
    "                                        for i in range(new_instance.H)])[0] # H x samples\n",
    "        elif approximate == \"empirical\":\n",
    "            new_instance.bootstrap_forecasts = np.column_stack([np.random.choice(new_instance.resid[i], size=samples, replace=True)+y_forecast[i]\n",
    "                for i in range(self.H)]).T\n",
    "        else:\n",
    "            raise ValueError(\"approximate must be 'kde' or 'empirical'.\")\n",
    "\n",
    "        new_instance.bootstrap_forecasts_df = pd.DataFrame(new_instance.bootstrap_forecasts.T, columns=[f'h_{i+1}' for i in range(self.H)])\n",
    "        new_instance.y_forecast_b = y_forecast\n",
    "\n",
    "        return new_instance\n",
    "\n",
    "    def bootstrap_quantiles(self, quantiles, bootstrap_method='bootstrap'):\n",
    "        \"\"\"\n",
    "        Generate bootstrap quantiles for future time steps.\n",
    "        Args:\n",
    "            quantiles (float or list): Quantiles to be calculated (e.g., 0.1, 0.5, 0.9).\n",
    "            bootstrap_method (str): The method to use for bootstrapping or simulated correlated_forecasts ('bootstrap' or 'correlated').\n",
    "        \"\"\"\n",
    "        ## Make sure bootstrap() method is called before calling this method\n",
    "        if bootstrap_method == 'bootstrap':\n",
    "            if (not hasattr(self, 'bootstrap')):\n",
    "                raise RuntimeError(\"Bootstrap samples not available. Run .bootstrap(df) first.\")\n",
    "            return get_bootstrap_quantiles(self.bootstrap_forecasts, self.n_calib, quantiles, self.y_forecast_b)\n",
    "        elif bootstrap_method == 'correlated':\n",
    "            if (not hasattr(self, 'simulate_correlated_forecasts')):\n",
    "                raise RuntimeError(\"Correlated forecast samples not available. Run .simulate_correlated_forecasts(df) first.\")\n",
    "            return get_bootstrap_quantiles(self.w_samples.T, self.n_calib, quantiles, self.y_forecast_c)\n",
    "\n",
    "    def simulate_correlated_forecasts(self, df, samples=1000, future_exog=None):\n",
    "        \"\"\"\n",
    "        Simulate correlated errors to generate forecasts\n",
    "        Parameters:\n",
    "        - df: DataFrame containing the training data\n",
    "        - samples: number of samples to generate\n",
    "        - future_exog: optional exogenous variables for forecasting\n",
    "        Returns:\n",
    "        - DataFrame containing the simulated forecasts\n",
    "        \"\"\"\n",
    "        if not hasattr(self, 'resid'):\n",
    "            raise RuntimeError(\"Residuals not available. Run .non_conformity_scores(df) .calibrate(df) or  first.\")\n",
    "        y_train = df[self.target_col]\n",
    "        x_train = df.drop(columns=[self.target_col])\n",
    "        if future_exog is not None:\n",
    "            y_forecast = self.model.forecast(y=np.array(y_train), h=self.H, X=np.array(x_train),\n",
    "                    X_future=np.array(future_exog))[\"mean\"]\n",
    "        else:\n",
    "            y_forecast = self.model.forecast(y=np.array(y_train), h=self.H, X=np.array(x_train))[\"mean\"]\n",
    "\n",
    "        mu = np.mean(self.resid.T, axis=0)\n",
    "        sigma_ = np.cov(self.resid.T, rowvar=False, ddof=1)\n",
    "\n",
    "        rng = np.random.default_rng(seed=42)\n",
    "        samples = rng.multivariate_normal(mu, sigma_, size=samples)\n",
    "        self.w_samples = samples + y_forecast\n",
    "        self.correlated_forecasts = pd.DataFrame(self.w_samples, columns=[f'h_{i+1}' for i in range(self.H)])\n",
    "        self.y_forecast_c = y_forecast\n",
    "        return self\n",
    "    \n",
    "class bidirect_ts_conformalizer():\n",
    "    def __init__(self, delta, train_df, col_index, n_windows, model, H, calib_metric = \"mae\", model_param=None):\n",
    "        self.delta = delta\n",
    "        self.model = model\n",
    "        self.train_df = train_df\n",
    "        self.n_windows = n_windows\n",
    "        self.n_calib = n_windows\n",
    "        self.H = H\n",
    "        self.calib_metric = calib_metric\n",
    "        self.param = model_param\n",
    "        self.col=col_index\n",
    "        self.calibrate()\n",
    "    def backtest(self):\n",
    "        actuals = []\n",
    "        predictions = []\n",
    "        for i in range(self.n_windows):\n",
    "            x_back = self.train_df[:-self.H-i]\n",
    "            if i !=0:\n",
    "                test_y = self.train_df[-self.H-i:-i].iloc[:, self.col]\n",
    "                if len(self.train_df.columns)>1:\n",
    "                    test_x = self.train_df[-self.H-i:-i].iloc[:, 2:]\n",
    "                else:\n",
    "                    test_x = None\n",
    "            else:\n",
    "                test_y = self.train_df[-self.H:].iloc[:, self.col]\n",
    "                if len(self.train_df.columns)>1:\n",
    "                    test_x = self.train_df[-self.H:].iloc[:, 2:]\n",
    "                else:\n",
    "                    test_x = None\n",
    "                \n",
    "#             mod_arima = ARIMA(y_back, exog=x_back, order = (0,1,2), seasonal_order=(0,1,1, 7)).fit()\n",
    "#             y_pred = mod_arima.forecast(self.H, exog = test_x)\n",
    "            \n",
    "            if self.param is not None:\n",
    "                self.model.fit(x_back, param=self.param)\n",
    "            else:\n",
    "                self.model.fit(x_back)\n",
    "            if test_x is not None:\n",
    "                forecast = self.model.forecast(self.H, test_x)[self.col]\n",
    "            else:\n",
    "                forecast = self.model.forecast(self.H)[self.col]\n",
    "            \n",
    "            test_y = np.array(test_y)\n",
    "            predictions.append(forecast)\n",
    "            actuals.append(test_y)\n",
    "            print(\"model \"+str(i+1)+\" is completed\")\n",
    "        return np.row_stack(actuals), np.row_stack(predictions)\n",
    "    \n",
    "    def calculate_qunatile(self, scores_calib):\n",
    "        # Calculate the quantile values for each delta and non-conformity scores\n",
    "        delta_q = []\n",
    "        for i in self.delta:\n",
    "            which_quantile = np.ceil((i)*(self.n_calib+1))/self.n_calib\n",
    "            q_data = np.quantile(scores_calib, which_quantile, method = \"lower\")\n",
    "            delta_q.append(q_data)\n",
    "        self.delta_q = delta_q\n",
    "        return delta_q\n",
    "    \n",
    "    def non_conformity_func(self):\n",
    "        acts, preds = self.backtest()\n",
    "        horizon_scores = []\n",
    "        dists = []\n",
    "        for i in range(self.H):\n",
    "            # calculating metrics horizon i\n",
    "            mae =np.abs(acts[:,i] - preds[:,i]) \n",
    "            smape = 2*mae/(np.abs(acts[:,i])+np.abs(preds[:,i]))\n",
    "            mape = mae/acts[:,i]\n",
    "            metrics = np.stack((smape,  mape, mae), axis=1)\n",
    "            horizon_scores.append(metrics)\n",
    "            dist = 2*acts[:,i] - preds[:,i]\n",
    "            dists.append(dist)\n",
    "        self.cp_dist = np.stack(dists).T\n",
    "        return horizon_scores\n",
    "    \n",
    "    \n",
    "    def calibrate(self):\n",
    "         # Calibrate the conformalizer to calculate q_hat\n",
    "        scores_calib = self.non_conformity_func()\n",
    "        self.q_hat_D = []\n",
    "        for d in range(len(self.delta)):\n",
    "            q_hat_H = []\n",
    "            for i in range(self.H):\n",
    "                scores_i = scores_calib[i]\n",
    "                if self.calib_metric == \"smape\":\n",
    "                    q_hat = self.calculate_qunatile(scores_i[:, 0])[d]\n",
    "                elif self.calib_metric == \"mape\":\n",
    "                    q_hat = self.calculate_qunatile(scores_i[:, 1])[d]\n",
    "                elif self.calib_metric == \"mae\":\n",
    "                    q_hat = self.calculate_qunatile(scores_i[:, 2])[d]\n",
    "                else:\n",
    "                    raise ValueError(\"not a valid metric\")\n",
    "                q_hat_H.append(q_hat)\n",
    "            self.q_hat_D.append(q_hat_H)\n",
    "            \n",
    "    def forecast(self, X=None):\n",
    "        if self.param is not None:\n",
    "            self.model.fit(self.train_df, param=self.param)\n",
    "        else:\n",
    "            self.model.fit(self.train_df)\n",
    "            \n",
    "        if X is not None:\n",
    "            y_pred = self.model.forecast(self.H, X)[self.col]\n",
    "        else:\n",
    "            y_pred = self.model.forecast(self.H)[self.col]\n",
    "            \n",
    "        result = []\n",
    "        result.append(y_pred)\n",
    "        for i in range(len(self.delta)):\n",
    "            if self.calib_metric == \"mae\":\n",
    "                y_lower, y_upper = y_pred - np.array(self.q_hat_D[i]).flatten(), y_pred + np.array(self.q_hat_D[i]).flatten()\n",
    "            elif self.calib_metric == \"mape\":\n",
    "                y_lower, y_upper = y_pred/(1+np.array(self.q_hat_D[i]).flatten()), y_pred/(1-np.array(self.q_hat_D[i]).flatten())\n",
    "            elif self.calib_metric == \"smape\":\n",
    "                y_lower = y_pred*(2-np.array(self.q_hat_D[i]).flatten())/(2+np.array(self.q_hat_D[i]).flatten())\n",
    "                y_upper = y_pred*(2+np.array(self.q_hat_D[i]).flatten())/(2-np.array(self.q_hat_D[i]).flatten())\n",
    "            else:\n",
    "                raise ValueError(\"not a valid metric\")\n",
    "            result.append(y_lower)\n",
    "            result.append(y_upper)\n",
    "        CPs = pd.DataFrame(result).T\n",
    "        CPs.rename(columns = {0:\"point_forecast\"}, inplace = True)\n",
    "        for i in range(0, 2*len(self.delta), 2):\n",
    "            d_index = round(i/2)\n",
    "            CPs.rename(columns = {i+1:\"lower_\"+str(round(self.delta[d_index]*100)), i+2:\"upper_\"+str(round(self.delta[d_index]*100))}, inplace = True)\n",
    "        return CPs\n",
    "    \n",
    "class bag_boost_aggr_conformalizer():\n",
    "    def __init__(self, delta, train_df, n_windows, models, cat_cols, H, calib_metric = \"mae\", model_param=None):\n",
    "        self.delta = delta\n",
    "        self.models = models\n",
    "        self.train_df = train_df\n",
    "        self.cats = cat_cols\n",
    "        self.n_windows = n_windows\n",
    "        self.n_calib = n_windows\n",
    "        self.H = H\n",
    "        self.calib_metric = calib_metric\n",
    "        self.param = model_param\n",
    "        self.cols = [m.target_col for m in self.models]\n",
    "        \n",
    "        self.models_f = self.models.copy()\n",
    "        for i, j in zip(self.cols, range(len(self.cols))):\n",
    "            train = pd.concat([self.train_df[i], self.train_df[self.cats]], axis=1)\n",
    "            # self.models[i] = ExponentialSmoothing(self.train[i], **self.params[i][0]).fit(**self.params[i][1])\n",
    "            self.models_f[j].fit(train, self.param[i])\n",
    "\n",
    "        \n",
    "        self.calibrate()\n",
    "    def backtest(self):\n",
    "        actuals = []\n",
    "        predictions = []\n",
    "        for i in range(self.n_windows):\n",
    "            sum_forecasts = np.zeros((self.H,))\n",
    "            sum_actuals = np.zeros((self.H,))\n",
    "            for m in self.models:\n",
    "                bactest_df = pd.concat([self.train_df[m.target_col], self.train_df[self.cats]], axis=1)\n",
    "                x_back = bactest_df[:-self.H-i]\n",
    "                if i !=0:\n",
    "                    test_y = bactest_df[-self.H-i:-i][m.target_col]\n",
    "                    if len(bactest_df.columns)>1:\n",
    "                        test_x = bactest_df[-self.H-i:-i].iloc[:, 1:]\n",
    "                    else:\n",
    "                        test_x = None\n",
    "                else:\n",
    "                    test_y = bactest_df[-self.H:][m.target_col]\n",
    "                    if len(bactest_df.columns)>1:\n",
    "                        test_x = bactest_df[-self.H:].iloc[:, 1:]\n",
    "                    else:\n",
    "                        test_x = None\n",
    "                    \n",
    "\n",
    "                \n",
    "                if self.param is not None:\n",
    "                    m.fit(x_back, param=self.param[m.target_col])\n",
    "                else:\n",
    "                    m.fit(x_back)\n",
    "                if test_x is not None:\n",
    "                    forecast = m.forecast(self.H, test_x)\n",
    "                else:\n",
    "                    forecast = m.forecast(self.H)\n",
    "                sum_forecasts +=forecast\n",
    "                sum_actuals +=np.array(test_y)\n",
    "            \n",
    "            predictions.append(sum_forecasts)\n",
    "            actuals.append(sum_actuals)\n",
    "            print(\"model \"+str(i+1)+\" is completed\")\n",
    "        self.predictions = np.row_stack(predictions)\n",
    "        self.actuals = np.row_stack(actuals)\n",
    "        return np.row_stack(actuals), np.row_stack(predictions)\n",
    "    \n",
    "    def calculate_qunatile(self, scores_calib):\n",
    "        # Calculate the quantile values for each delta and non-conformity scores\n",
    "        delta_q = []\n",
    "        for i in self.delta:\n",
    "            which_quantile = np.ceil((i)*(self.n_calib+1))/self.n_calib\n",
    "            q_data = np.quantile(scores_calib, which_quantile, method = \"lower\")\n",
    "            delta_q.append(q_data)\n",
    "        self.delta_q = delta_q\n",
    "        return delta_q\n",
    "    \n",
    "    def non_conformity_func(self):\n",
    "        acts, preds = self.backtest()\n",
    "        horizon_scores = []\n",
    "        dists = []\n",
    "        for i in range(self.H):\n",
    "            # calculating metrics horizon i\n",
    "            mae =np.abs(acts[:,i] - preds[:,i]) \n",
    "            smape = 2*mae/(np.abs(acts[:,i])+np.abs(preds[:,i]))\n",
    "            mape = mae/acts[:,i]\n",
    "            metrics = np.stack((smape,  mape, mae), axis=1)\n",
    "            horizon_scores.append(metrics)\n",
    "            dist = 2*acts[:,i] - preds[:,i]\n",
    "            dists.append(dist)\n",
    "        self.cp_dist = np.stack(dists).T\n",
    "        return horizon_scores\n",
    "    \n",
    "    \n",
    "    def calibrate(self):\n",
    "         # Calibrate the conformalizer to calculate q_hat\n",
    "        scores_calib = self.non_conformity_func()\n",
    "        self.q_hat_D = []\n",
    "        for d in range(len(self.delta)):\n",
    "            q_hat_H = []\n",
    "            for i in range(self.H):\n",
    "                scores_i = scores_calib[i]\n",
    "                if self.calib_metric == \"smape\":\n",
    "                    q_hat = self.calculate_qunatile(scores_i[:, 0])[d]\n",
    "                elif self.calib_metric == \"mape\":\n",
    "                    q_hat = self.calculate_qunatile(scores_i[:, 1])[d]\n",
    "                elif self.calib_metric == \"mae\":\n",
    "                    q_hat = self.calculate_qunatile(scores_i[:, 2])[d]\n",
    "                else:\n",
    "                    raise ValueError(\"not a valid metric\")\n",
    "                q_hat_H.append(q_hat)\n",
    "            self.q_hat_D.append(q_hat_H)\n",
    "            \n",
    "    def forecast(self, X=None):\n",
    "\n",
    "        y_pred = np.zeros((self.H,))\n",
    "        for f in self.models_f:\n",
    "            # y_pred += self.models_f[i].forecast(self.H,  x_test= X)\n",
    "            if X is not None:\n",
    "                y_pred += f.forecast(self.H,  X)\n",
    "            else:\n",
    "                y_pred += f.forecast(self.H)\n",
    "            \n",
    "        result = []\n",
    "        result.append(y_pred)\n",
    "        for i in range(len(self.delta)):\n",
    "            if self.calib_metric == \"mae\":\n",
    "                y_lower, y_upper = y_pred - np.array(self.q_hat_D[i]).flatten(), y_pred + np.array(self.q_hat_D[i]).flatten()\n",
    "            elif self.calib_metric == \"mape\":\n",
    "                y_lower, y_upper = y_pred/(1+np.array(self.q_hat_D[i]).flatten()), y_pred/(1-np.array(self.q_hat_D[i]).flatten())\n",
    "            elif self.calib_metric == \"smape\":\n",
    "                y_lower = y_pred*(2-np.array(self.q_hat_D[i]).flatten())/(2+np.array(self.q_hat_D[i]).flatten())\n",
    "                y_upper = y_pred*(2+np.array(self.q_hat_D[i]).flatten())/(2-np.array(self.q_hat_D[i]).flatten())\n",
    "            else:\n",
    "                raise ValueError(\"not a valid metric\")\n",
    "            result.append(y_lower)\n",
    "            result.append(y_upper)\n",
    "        CPs = pd.DataFrame(result).T\n",
    "        CPs.rename(columns = {0:\"point_forecast\"}, inplace = True)\n",
    "        for i in range(0, 2*len(self.delta), 2):\n",
    "            d_index = round(i/2)\n",
    "            CPs.rename(columns = {i+1:\"lower_\"+str(round(self.delta[d_index]*100)), i+2:\"upper_\"+str(round(self.delta[d_index]*100))}, inplace = True)\n",
    "        return CPs\n",
    "    \n",
    "class bidirect_aggr_conformalizer():\n",
    "    def __init__(self, delta, train_df, col_index, n_windows, models, cat_cols, H, calib_metric = \"mae\", model_param=None):\n",
    "        self.delta = delta\n",
    "        self.models = models\n",
    "        self.cats = cat_cols\n",
    "        self.idx = col_index\n",
    "        self.train_df = train_df\n",
    "        self.n_windows = n_windows\n",
    "        self.n_calib = n_windows\n",
    "        self.H = H\n",
    "        self.calib_metric = calib_metric\n",
    "        self.param = model_param\n",
    "        # self.col=col_index\n",
    "        \n",
    "        self.models_f = self.models.copy()\n",
    "        for f, j in zip(self.models_f, range(len(self.models_f))):\n",
    "            train = pd.concat([self.train_df[f.target_col], self.train_df[self.cats]], axis=1)\n",
    "            # self.models[i] = ExponentialSmoothing(self.train[i], **self.params[i][0]).fit(**self.params[i][1])\n",
    "            self.models_f[j].fit(train, self.param[f.target_col[self.idx]])\n",
    "        self.calibrate()\n",
    "    def backtest(self):\n",
    "        actuals = []\n",
    "        predictions = []\n",
    "        for i in range(self.n_windows):\n",
    "            sum_forecasts = np.zeros((self.H,))\n",
    "            sum_actuals = np.zeros((self.H,))\n",
    "            for m in self.models:\n",
    "                bactest_df = pd.concat([self.train_df[m.target_col], self.train_df[self.cats]], axis=1)\n",
    "                x_back = bactest_df[:-self.H-i]\n",
    "                if i !=0:\n",
    "                    test_y = bactest_df[-self.H-i:-i][m.target_col[self.idx]]\n",
    "                    if len(bactest_df.columns)>1:\n",
    "                        test_x = bactest_df[-self.H-i:-i].iloc[:, 2:]\n",
    "                    else:\n",
    "                        test_x = None\n",
    "                else:\n",
    "                    test_y = bactest_df[-self.H:][m.target_col[self.idx]]\n",
    "                    if len(bactest_df.columns)>1:\n",
    "                        test_x = bactest_df[-self.H:].iloc[:, 2:]\n",
    "                    else:\n",
    "                        test_x = None\n",
    "                    \n",
    "    #             mod_arima = ARIMA(y_back, exog=x_back, order = (0,1,2), seasonal_order=(0,1,1, 7)).fit()\n",
    "    #             y_pred = mod_arima.forecast(self.H, exog = test_x)\n",
    "                \n",
    "                if self.param is not None:\n",
    "                    m.fit(x_back, param=self.param[m.target_col[self.idx]])\n",
    "                else:\n",
    "                    m.fit(x_back)\n",
    "                if test_x is not None:\n",
    "                    forecast = m.forecast(self.H, test_x)[self.idx]\n",
    "                else:\n",
    "                    forecast = m.forecast(self.H)[self.idx]\n",
    "                sum_forecasts +=forecast\n",
    "                sum_actuals +=np.array(test_y)\n",
    "            \n",
    "            predictions.append(sum_forecasts)\n",
    "            actuals.append(sum_actuals)\n",
    "            print(\"model \"+str(i+1)+\" is completed\")\n",
    "        self.predictions = np.row_stack(predictions)\n",
    "        self.actuals = np.row_stack(actuals)\n",
    "        return np.row_stack(actuals), np.row_stack(predictions)\n",
    "    \n",
    "    def calculate_qunatile(self, scores_calib):\n",
    "        # Calculate the quantile values for each delta and non-conformity scores\n",
    "        delta_q = []\n",
    "        for i in self.delta:\n",
    "            which_quantile = np.ceil((i)*(self.n_calib+1))/self.n_calib\n",
    "            q_data = np.quantile(scores_calib, which_quantile, method = \"lower\")\n",
    "            delta_q.append(q_data)\n",
    "        self.delta_q = delta_q\n",
    "        return delta_q\n",
    "    \n",
    "    def non_conformity_func(self):\n",
    "        acts, preds = self.backtest()\n",
    "        horizon_scores = []\n",
    "        dists = []\n",
    "        for i in range(self.H):\n",
    "            # calculating metrics horizon i\n",
    "            mae =np.abs(acts[:,i] - preds[:,i]) \n",
    "            smape = 2*mae/(np.abs(acts[:,i])+np.abs(preds[:,i]))\n",
    "            mape = mae/acts[:,i]\n",
    "            metrics = np.stack((smape,  mape, mae), axis=1)\n",
    "            horizon_scores.append(metrics)\n",
    "            dist = 2*acts[:,i] - preds[:,i]\n",
    "            dists.append(dist)\n",
    "        self.cp_dist = np.stack(dists).T\n",
    "        return horizon_scores\n",
    "    \n",
    "    \n",
    "    def calibrate(self):\n",
    "         # Calibrate the conformalizer to calculate q_hat\n",
    "        scores_calib = self.non_conformity_func()\n",
    "        self.q_hat_D = []\n",
    "        for d in range(len(self.delta)):\n",
    "            q_hat_H = []\n",
    "            for i in range(self.H):\n",
    "                scores_i = scores_calib[i]\n",
    "                if self.calib_metric == \"smape\":\n",
    "                    q_hat = self.calculate_qunatile(scores_i[:, 0])[d]\n",
    "                elif self.calib_metric == \"mape\":\n",
    "                    q_hat = self.calculate_qunatile(scores_i[:, 1])[d]\n",
    "                elif self.calib_metric == \"mae\":\n",
    "                    q_hat = self.calculate_qunatile(scores_i[:, 2])[d]\n",
    "                else:\n",
    "                    raise ValueError(\"not a valid metric\")\n",
    "                q_hat_H.append(q_hat)\n",
    "            self.q_hat_D.append(q_hat_H)\n",
    "            \n",
    "    def forecast(self, X=None):\n",
    "\n",
    "        y_pred = np.zeros((self.H,))\n",
    "        for f in self.models_f:\n",
    "            # y_pred += self.models_f[i].forecast(self.H,  x_test= X)\n",
    "            if X is not None:\n",
    "                y_pred += f.forecast(self.H,  x_test= X)[self.idx]\n",
    "            else:\n",
    "                y_pred += f.forecast(self.H)[self.idx]\n",
    "            \n",
    "        result = []\n",
    "        result.append(y_pred)\n",
    "        for i in range(len(self.delta)):\n",
    "            if self.calib_metric == \"mae\":\n",
    "                y_lower, y_upper = y_pred - np.array(self.q_hat_D[i]).flatten(), y_pred + np.array(self.q_hat_D[i]).flatten()\n",
    "            elif self.calib_metric == \"mape\":\n",
    "                y_lower, y_upper = y_pred/(1+np.array(self.q_hat_D[i]).flatten()), y_pred/(1-np.array(self.q_hat_D[i]).flatten())\n",
    "            elif self.calib_metric == \"smape\":\n",
    "                y_lower = y_pred*(2-np.array(self.q_hat_D[i]).flatten())/(2+np.array(self.q_hat_D[i]).flatten())\n",
    "                y_upper = y_pred*(2+np.array(self.q_hat_D[i]).flatten())/(2-np.array(self.q_hat_D[i]).flatten())\n",
    "            else:\n",
    "                raise ValueError(\"not a valid metric\")\n",
    "            result.append(y_lower)\n",
    "            result.append(y_upper)\n",
    "        CPs = pd.DataFrame(result).T\n",
    "        CPs.rename(columns = {0:\"point_forecast\"}, inplace = True)\n",
    "        for i in range(0, 2*len(self.delta), 2):\n",
    "            d_index = round(i/2)\n",
    "            CPs.rename(columns = {i+1:\"lower_\"+str(round(self.delta[d_index]*100)), i+2:\"upper_\"+str(round(self.delta[d_index]*100))}, inplace = True)\n",
    "        return CPs\n",
    "\n",
    "class ets_aggr_conformalizer():\n",
    "    def __init__(self, train_data, tar_cols, delta, params, n_windows, H, calib_metric = \"mae\"):\n",
    "        self.delta = delta\n",
    "        self.train = train_data\n",
    "        self.n_windows = n_windows\n",
    "        self.n_calib = n_windows\n",
    "        self.H = H\n",
    "        self.cols = tar_cols\n",
    "        self.params = params\n",
    "        self.calib_metric = calib_metric\n",
    "        self.models = {}\n",
    "        for i in self.cols:\n",
    "            self.models[i] = ExponentialSmoothing(self.train[i], **self.params[i][0]).fit(**self.params[i][1])\n",
    "        self.calibrate()\n",
    "    def backtest(self):\n",
    "        #making H-step-ahead forecast n_windows times for each 1-step backward sliding window.\n",
    "        # We can the think of n_windows as the size of calibration set for each H horizon \n",
    "        actuals = []\n",
    "        predictions = []\n",
    "        for i in range(self.n_windows):\n",
    "            sum_forecasts = np.zeros((self.H,))\n",
    "            sum_actuals = np.zeros((self.H,))\n",
    "            for j in self.cols:\n",
    "                y_train = self.train[:-self.H-i][j]\n",
    "                if i !=0:\n",
    "                    y_test = self.train[-self.H-i:-i][j]\n",
    "                else:\n",
    "                    y_test = self.train[-self.H:][j]\n",
    "    \n",
    "                model_ets = ExponentialSmoothing(y_train, **self.params[j][0])\n",
    "                fit_ets = model_ets.fit(**self.params[j][1])\n",
    "        \n",
    "                y_pred = np.array(fit_ets.forecast(self.H))\n",
    "                sum_forecasts +=y_pred\n",
    "                sum_actuals +=np.array(y_test)\n",
    "            \n",
    "            predictions.append(sum_forecasts)\n",
    "            actuals.append(sum_actuals)\n",
    "            print(\"model \"+str(i+1)+\" is completed\")\n",
    "        self.predictions = np.row_stack(predictions)\n",
    "        self.actuals = np.row_stack(actuals)\n",
    "        return np.row_stack(actuals), np.row_stack(predictions)\n",
    "\n",
    "    \n",
    "    def calculate_qunatile(self, scores_calib):\n",
    "        # Calculate the quantile values for each delta value\n",
    "        delta_q = []\n",
    "        for i in self.delta:\n",
    "            which_quantile = np.ceil((i)*(self.n_calib+1))/self.n_calib\n",
    "            q_data = np.quantile(scores_calib, which_quantile, method = \"lower\")\n",
    "            delta_q.append(q_data)\n",
    "        self.delta_q = delta_q\n",
    "        return delta_q\n",
    "    \n",
    "    def non_conformity_func(self):\n",
    "        #Calculate non-conformity scores (mae, smape and mape for now) for each forecasted horizon\n",
    "        acts, preds = self.backtest()\n",
    "        horizon_scores = []\n",
    "        dists = []\n",
    "        for i in range(self.H):\n",
    "            mae =np.abs(acts[:,i] - preds[:,i])\n",
    "            smape = 2*mae/(np.abs(acts[:,i])+np.abs(preds[:,i]))\n",
    "            mape = mae/acts[:,i]\n",
    "            metrics = np.stack((smape,  mape, mae), axis=1)\n",
    "            horizon_scores.append(metrics)\n",
    "            dist = 2*acts[:,i] - preds[:,i]\n",
    "            dists.append(dist)\n",
    "        self.cp_dist = np.stack(dists).T\n",
    "        return horizon_scores\n",
    "    \n",
    "    \n",
    "    def calibrate(self):\n",
    "         # Calibrate the conformalizer to calculate q_hat for all given delta values\n",
    "        scores_calib = self.non_conformity_func()\n",
    "        self.q_hat_D = []\n",
    "        for d in range(len(self.delta)):\n",
    "            q_hat_H = []\n",
    "            for i in range(self.H):\n",
    "                scores_i = scores_calib[i]\n",
    "                if self.calib_metric == \"smape\":\n",
    "                    qhat = self.calculate_qunatile(scores_i[:, 0])[d]\n",
    "                elif self.calib_metric == \"mape\":\n",
    "                    qhat = self.calculate_qunatile(scores_i[:, 1])[d]\n",
    "                elif self.calib_metric == \"mae\":\n",
    "                    q_hat = self.calculate_qunatile(scores_i[:, 2])[d]\n",
    "                else:\n",
    "                    raise ValueError(\"not a valid metric\")\n",
    "                q_hat_H.append(q_hat)\n",
    "            self.q_hat_D.append(q_hat_H)\n",
    "            \n",
    "    def forecast(self):\n",
    "        y_pred = np.zeros((self.H,))\n",
    "        for i in self.cols:\n",
    "            y_pred += np.array(self.models[i].forecast(self.H))\n",
    "\n",
    "        result = []\n",
    "        result.append(y_pred)\n",
    "        #Calculate the prediction intervals given the calibration metric used for non-conformity score\n",
    "        for i in range(len(self.delta)):\n",
    "            if self.calib_metric == \"mae\":\n",
    "                y_lower, y_upper = y_pred - np.array(self.q_hat_D[i]).flatten(), y_pred + np.array(self.q_hat_D[i]).flatten()\n",
    "            elif self.calib_metric == \"mape\":\n",
    "                y_lower, y_upper = y_pred/(1+np.array(self.q_hat_D[i]).flatten()), y_pred/(1-np.array(self.q_hat_D[i]).flatten())\n",
    "            elif self.calib_metric == \"smape\":\n",
    "                y_lower = y_pred*(2-np.array(self.q_hat_D[i]).flatten())/(2+np.array(self.q_hat_D[i]).flatten())\n",
    "                y_upper = y_pred*(2+np.array(self.q_hat_D[i]).flatten())/(2-np.array(self.q_hat_D[i]).flatten())\n",
    "            else:\n",
    "                raise ValueError(\"not a valid metric\")\n",
    "            result.append(y_lower)\n",
    "            result.append(y_upper)\n",
    "        CPs = pd.DataFrame(result).T\n",
    "        CPs.rename(columns = {0:\"point_forecast\"}, inplace = True)\n",
    "        for i in range(0, 2*len(self.delta), 2):\n",
    "            d_index = round(i/2)\n",
    "            CPs.rename(columns = {i+1:\"lower_\"+str(round(self.delta[d_index]*100)), i+2:\"upper_\"+str(round(self.delta[d_index]*100))}, inplace = True)\n",
    "        return CPs\n",
    "    \n",
    "class s_arima_aggr_conformalizer():\n",
    "    def __init__(self, train_data, tar_cols, orders, delta, n_windows, H, exog = None, calib_metric = \"mae\"):\n",
    "        self.delta = delta\n",
    "        self.orders = orders\n",
    "        self.cols = tar_cols\n",
    "        self.train = train_data\n",
    "        self.exog = exog\n",
    "        self.n_windows = n_windows\n",
    "        self.n_calib = n_windows\n",
    "        self.H = H\n",
    "        self.calib_metric = calib_metric\n",
    "\n",
    "        self.models = {}\n",
    "        for i in self.cols:\n",
    "            # self.models[i] = ExponentialSmoothing(self.train[i], **self.params[i][0]).fit(**self.params[i][1])\n",
    "            self.models[i] = ARIMA(order=(self.orders[i][0],self.orders[i][5],self.orders[i][1]),\n",
    "                                   seasonal_order=(self.orders[i][2],self.orders[i][6],self.orders[i][3]),\n",
    "                                   season_length=self.orders[i][4]).fit(y=np.array(self.train[i]), X=np.array(self.exog, dtype = np.float64))\n",
    "\n",
    "            # y_pred = arima_m.forecast(y=y_train, h=test_size, X=x_train, X_future=x_test)[\"mean\"]\n",
    "            # self.models[i] = self.models[i].fit(y=y_train, X=x_train)\n",
    "            \n",
    "        self.calibrate()\n",
    "    def backtest(self):\n",
    "        #making H-step-ahead forecast n_windows times for each 1-step backward sliding window.\n",
    "        # We can the think of n_windows as the size of calibration set for each H horizon \n",
    "        actuals = []\n",
    "        predictions = []\n",
    "        for i in range(self.n_windows):\n",
    "            sum_forecasts = np.zeros((self.H,))\n",
    "            sum_actuals = np.zeros((self.H,))\n",
    "            for j in self.cols:\n",
    "                y_back = np.array(self.train[:-self.H-i][j])\n",
    "                if self.exog is not None:\n",
    "                    x_back = np.array(self.exog[:-self.H-i], dtype = np.float64)\n",
    "                else:\n",
    "                    x_back = None\n",
    "                if i !=0:\n",
    "                    test_y = np.array(self.train[-self.H-i:-i][j])\n",
    "                    if self.exog is not None:\n",
    "                        test_x = np.array(self.exog[-self.H-i:-i], np.float64)\n",
    "                    else:\n",
    "                        test_x = None\n",
    "                else:\n",
    "                    test_y = np.array(self.train[-self.H:][j])\n",
    "                    if self.exog is not None:\n",
    "                        test_x = np.array(self.exog[-self.H:], np.float64)\n",
    "                    else:\n",
    "                        test_x = None\n",
    "                    \n",
    "                # mod_arima = self.model(y_back, exog=x_back, order = self.order, seasonal_order=self.S_order).fit()\n",
    "                mod_arima = ARIMA(order=(self.orders[j][0],self.orders[j][5],self.orders[j][1]),\n",
    "                                   seasonal_order=(self.orders[j][2],self.orders[j][6],self.orders[j][3]),\n",
    "                                   season_length=self.orders[j][4]).fit(y=y_back, X=x_back)\n",
    "                # y_pred = mod_arima.forecast(self.H, exog = test_x)\n",
    "                y_pred = mod_arima.predict(self.H,  X=test_x)[\"mean\"]\n",
    "                sum_forecasts +=y_pred\n",
    "                sum_actuals +=test_y\n",
    "            \n",
    "            predictions.append(sum_forecasts)\n",
    "            actuals.append(sum_actuals)\n",
    "            print(\"model \"+str(i+1)+\" is completed\")\n",
    "        self.predictions = np.row_stack(predictions)\n",
    "        self.actuals = np.row_stack(actuals)\n",
    "        return np.row_stack(actuals), np.row_stack(predictions)\n",
    "    \n",
    "    def calculate_qunatile(self, scores_calib):\n",
    "        # Calculate the quantile values for each delta value\n",
    "        delta_q = []\n",
    "        for i in self.delta:\n",
    "            which_quantile = np.ceil((i)*(self.n_calib+1))/self.n_calib\n",
    "            q_data = np.quantile(scores_calib, which_quantile, method = \"lower\")\n",
    "            delta_q.append(q_data)\n",
    "        self.delta_q = delta_q\n",
    "        return delta_q\n",
    "    \n",
    "    def non_conformity_func(self):\n",
    "        #Calculate non-conformity scores (mae, smape and mape for now) for each forecasted horizon\n",
    "        acts, preds = self.backtest()\n",
    "        horizon_scores = []\n",
    "        dists = []\n",
    "        for i in range(self.H):\n",
    "            mae =np.abs(acts[:,i] - preds[:,i])\n",
    "            smape = 2*mae/(np.abs(acts[:,i])+np.abs(preds[:,i]))\n",
    "            mape = mae/acts[:,i]\n",
    "            metrics = np.stack((smape,  mape, mae), axis=1)\n",
    "            horizon_scores.append(metrics)\n",
    "            dist = 2*acts[:,i] - preds[:,i]\n",
    "            dists.append(dist)\n",
    "        self.cp_dist = np.stack(dists).T\n",
    "        return horizon_scores\n",
    "    \n",
    "    \n",
    "    def calibrate(self):\n",
    "         # Calibrate the conformalizer to calculate q_hat for all given delta values\n",
    "        scores_calib = self.non_conformity_func()\n",
    "        self.q_hat_D = []\n",
    "        for d in range(len(self.delta)):\n",
    "            q_hat_H = []\n",
    "            for i in range(self.H):\n",
    "                scores_i = scores_calib[i]\n",
    "                if self.calib_metric == \"smape\":\n",
    "                    qhat = self.calculate_qunatile(scores_i[:, 0])[d]\n",
    "                elif self.calib_metric == \"mape\":\n",
    "                    qhat = self.calculate_qunatile(scores_i[:, 1])[d]\n",
    "                elif self.calib_metric == \"mae\":\n",
    "                    q_hat = self.calculate_qunatile(scores_i[:, 2])[d]\n",
    "                else:\n",
    "                    raise ValueError(\"not a valid metric\")\n",
    "                q_hat_H.append(q_hat)\n",
    "            self.q_hat_D.append(q_hat_H)\n",
    "            \n",
    "    def forecast(self, exog = None):\n",
    "        y_pred = np.zeros((self.H,))\n",
    "        for i in self.cols:\n",
    "            y_pred += self.models[i].predict(self.H,  X=np.array(exog, np.float64))[\"mean\"]\n",
    "            # y_pred += np.array(self.models[i].forecast(self.H))\n",
    "\n",
    "        result = []\n",
    "        result.append(y_pred)\n",
    "        #Calculate the prediction intervals given the calibration metric used for non-conformity score\n",
    "        for i in range(len(self.delta)):\n",
    "            if self.calib_metric == \"mae\":\n",
    "                y_lower, y_upper = y_pred - np.array(self.q_hat_D[i]).flatten(), y_pred + np.array(self.q_hat_D[i]).flatten()\n",
    "            elif self.calib_metric == \"mape\":\n",
    "                y_lower, y_upper = y_pred/(1+np.array(self.q_hat_D[i]).flatten()), y_pred/(1-np.array(self.q_hat_D[i]).flatten())\n",
    "            elif self.calib_metric == \"smape\":\n",
    "                y_lower = y_pred*(2-np.array(self.q_hat_D[i]).flatten())/(2+np.array(self.q_hat_D[i]).flatten())\n",
    "                y_upper = y_pred*(2+np.array(self.q_hat_D[i]).flatten())/(2-np.array(self.q_hat_D[i]).flatten())\n",
    "            else:\n",
    "                raise ValueError(\"not a valid metric\")\n",
    "            result.append(y_lower)\n",
    "            result.append(y_upper)\n",
    "        CPs = pd.DataFrame(result).T\n",
    "        CPs.rename(columns = {0:\"point_forecast\"}, inplace = True)\n",
    "        for i in range(0, 2*len(self.delta), 2):\n",
    "            d_index = round(i/2)\n",
    "            CPs.rename(columns = {i+1:\"lower_\"+str(round(self.delta[d_index]*100)), i+2:\"upper_\"+str(round(self.delta[d_index]*100))}, inplace = True)\n",
    "        return CPs\n",
    "    \n",
    "class var_aggr_conformalizer():\n",
    "    def __init__(self, train_data, exogs, tar_columns, delta, n_windows, H, col_index, lags, diffs, calib_metric = \"mae\"):\n",
    "        self.delta = delta\n",
    "        self.lag_order = lags\n",
    "        self.train = train_data\n",
    "        self.exogs = exogs\n",
    "        self.cols = tar_columns\n",
    "        self.n_windows = n_windows\n",
    "        self.n_calib = n_windows\n",
    "        self.H = H\n",
    "        self.idx = col_index\n",
    "        self.diffs = diffs\n",
    "        self.calib_metric = calib_metric\n",
    "        self.models = {}\n",
    "        self.last_vals = {i: [] for i in tar_columns}\n",
    "        for i in self.cols:\n",
    "            # self.models[i] = ExponentialSmoothing(self.train[i], **self.params[i][0]).fit(**self.params[i][1])\n",
    "            tar_col = self.train.columns[self.train.columns.str.contains(i)].tolist()\n",
    "            dfi = self.train[tar_col]\n",
    "            if self.diffs[i][0] ==1:\n",
    "                dfi[tar_col[0]] = dfi[tar_col[0]].diff()\n",
    "                self.last_vals[i].append(self.train[tar_col[0]][-1])\n",
    "            else:\n",
    "                self.last_vals[i].append(None)\n",
    "            if self.diffs[i][1] ==1:\n",
    "                dfi[tar_col[1]] = dfi[tar_col[1]].diff()\n",
    "                self.last_vals[i].append(self.train[tar_col[1]][-1])\n",
    "            else:\n",
    "                self.last_vals[i].append(None)\n",
    "                \n",
    "            if (self.diffs[i][0] ==1) | (self.diffs[i][1] ==1):\n",
    "                exog_f = exogs[1:]\n",
    "            else:\n",
    "                exog_f = exogs\n",
    "            dfi = dfi.dropna()\n",
    "\n",
    "            self.models[i] = VAR(dfi, exog=exog_f).fit(self.lag_order)\n",
    "        self.calibrate()\n",
    "    def backtest(self):\n",
    "        #making H-step-ahead forecast n_windows times for each 1-step backward sliding window.\n",
    "        # We can the think of n_windows as the size of calibration set for each H horizon \n",
    "        actuals = []\n",
    "        predictions = []\n",
    "        for i in range(self.n_windows):\n",
    "            sum_forecasts = np.zeros((self.H,))\n",
    "            sum_actuals = np.zeros((self.H,))\n",
    "            for j in self.cols:\n",
    "                tar_col = self.train.columns[self.train.columns.str.contains(j)].tolist()\n",
    "                dfj = self.train[tar_col]\n",
    "                if self.diffs[j][0] ==1:\n",
    "                    dfj[tar_col[0]] = dfj[tar_col[0]].diff()\n",
    "                if self.diffs[j][1] ==1:\n",
    "                    dfj[tar_col[1]] = dfj[tar_col[1]].diff()\n",
    "                    \n",
    "                y_back = dfj[:-self.H-i]\n",
    "                x_back = self.exogs[:-self.H-i]\n",
    "                \n",
    "                if i !=0:\n",
    "                    if self.diffs[j][self.idx] ==1:\n",
    "                        test_y = np.array(self.train[tar_col[self.idx]])[-self.H-i:-i]\n",
    "                        last_train = np.array(self.train[tar_col[self.idx]])[:-self.H-i][-1]\n",
    "                    else:\n",
    "                        test_y = np.array(self.train[tar_col[self.idx]])[-self.H-i:-i]\n",
    "                   \n",
    "                    test_x = self.exogs[-self.H-i:-i]\n",
    "\n",
    "                else:\n",
    "                    if self.diffs[j][self.idx] ==1:\n",
    "                        test_y = np.array(self.train[tar_col[self.idx]])[-self.H:]\n",
    "                        last_train = np.array(self.train[tar_col[self.idx]])[:-self.H-i][-1]\n",
    "                    else:\n",
    "                        test_y = np.array(self.train[tar_col[self.idx]])[-self.H:]\n",
    "                    test_x = self.exogs[-self.H:]\n",
    "                \n",
    "                y_back = y_back.dropna()\n",
    "                # y_back[self.idx].fillna(y_back[self.idx][17:33].mean())\n",
    "                # y_back = y_back.fillna(y_back.rolling(window=16, min_periods=1).mean().shift(-16 + 1)\n",
    "\n",
    "                if (self.diffs[j][0] ==1) | (self.diffs[j][1] ==1):\n",
    "                    x_back = x_back[1:]\n",
    "                    \n",
    "                var_result = VAR(y_back, exog=x_back).fit(self.lag_order)\n",
    "             \n",
    "                y_pred = var_result.forecast(y = y_back.values[-self.lag_order:], steps = self.H, exog_future = np.array(test_x))[:, self.idx]\n",
    "                \n",
    "                if self.diffs[j][self.idx] ==1:\n",
    "                    pred_dif = np.insert(y_pred, 0, last_train)\n",
    "                    sum_forecasts += np.cumsum(pred_dif)[-self.H:]\n",
    "                else:\n",
    "                    sum_forecasts += y_pred\n",
    "                    \n",
    "                sum_forecasts +=y_pred\n",
    "                sum_actuals +=test_y\n",
    "            \n",
    "            predictions.append(sum_forecasts)\n",
    "            actuals.append(sum_actuals)\n",
    "            print(\"model \"+str(i+1)+\" is completed\")\n",
    "        self.predictions = np.row_stack(predictions)\n",
    "        self.actuals = np.row_stack(actuals)\n",
    "        return np.row_stack(actuals), np.row_stack(predictions)\n",
    "    \n",
    "    def calculate_qunatile(self, scores_calib):\n",
    "        # Calculate the quantile values for each delta value\n",
    "        delta_q = []\n",
    "        for i in self.delta:\n",
    "            which_quantile = np.ceil((i)*(self.n_calib+1))/self.n_calib\n",
    "            q_data = np.quantile(scores_calib, which_quantile, method = \"lower\")\n",
    "            delta_q.append(q_data)\n",
    "        self.delta_q = delta_q\n",
    "        return delta_q\n",
    "    \n",
    "    def non_conformity_func(self):\n",
    "        #Calculate non-conformity scores (mae, smape and mape for now) for each forecasted horizon\n",
    "        acts, preds = self.backtest()\n",
    "        horizon_scores = []\n",
    "        dists = []\n",
    "        for i in range(self.H):\n",
    "            mae =np.abs(acts[:,i] - preds[:,i])\n",
    "            smape = 2*mae/(np.abs(acts[:,i])+np.abs(preds[:,i]))\n",
    "            mape = mae/acts[:,i]\n",
    "            metrics = np.stack((smape,  mape, mae), axis=1)\n",
    "            horizon_scores.append(metrics)\n",
    "            dist = 2*acts[:,i] - preds[:,i]\n",
    "            dists.append(dist)\n",
    "        self.cp_dist = np.stack(dists).T\n",
    "        return horizon_scores\n",
    "    \n",
    "    \n",
    "    def calibrate(self):\n",
    "         # Calibrate the conformalizer to calculate q_hat for all given delta values\n",
    "        scores_calib = self.non_conformity_func()\n",
    "        self.q_hat_D = []\n",
    "        for d in range(len(self.delta)):\n",
    "            q_hat_H = []\n",
    "            for i in range(self.H):\n",
    "                scores_i = scores_calib[i]\n",
    "                if self.calib_metric == \"smape\":\n",
    "                    qhat = self.calculate_qunatile(scores_i[:, 0])[d]\n",
    "                elif self.calib_metric == \"mape\":\n",
    "                    qhat = self.calculate_qunatile(scores_i[:, 1])[d]\n",
    "                elif self.calib_metric == \"mae\":\n",
    "                    q_hat = self.calculate_qunatile(scores_i[:, 2])[d]\n",
    "                else:\n",
    "                    raise ValueError(\"not a valid metric\")\n",
    "                q_hat_H.append(q_hat)\n",
    "            self.q_hat_D.append(q_hat_H)\n",
    "            \n",
    "    def forecast(self, X = None):\n",
    "        y_pred = np.zeros((self.H,))\n",
    "        for i in self.cols:\n",
    "            y_train = self.models[i].endog\n",
    "            # x_train = self.models[i].exog\n",
    "            fore_var = self.models[i].forecast(y = y_train[-self.lag_order:], steps = self.H, exog_future = np.array(X))[:, self.idx]\n",
    "            if self.diffs[i][self.idx] ==1:\n",
    "                last_origin = self.last_vals[i][self.idx]\n",
    "                add_orig = np.insert(fore_var, 0, last_origin)\n",
    "                y_pred += np.cumsum(add_orig)[-self.H:]\n",
    "            else:\n",
    "                y_pred += fore_var\n",
    "\n",
    "        result = []\n",
    "        result.append(y_pred)\n",
    "        #Calculate the prediction intervals given the calibration metric used for non-conformity score\n",
    "        for i in range(len(self.delta)):\n",
    "            if self.calib_metric == \"mae\":\n",
    "                y_lower, y_upper = y_pred - np.array(self.q_hat_D[i]).flatten(), y_pred + np.array(self.q_hat_D[i]).flatten()\n",
    "            elif self.calib_metric == \"mape\":\n",
    "                y_lower, y_upper = y_pred/(1+np.array(self.q_hat_D[i]).flatten()), y_pred/(1-np.array(self.q_hat_D[i]).flatten())\n",
    "            elif self.calib_metric == \"smape\":\n",
    "                y_lower = y_pred*(2-np.array(self.q_hat_D[i]).flatten())/(2+np.array(self.q_hat_D[i]).flatten())\n",
    "                y_upper = y_pred*(2+np.array(self.q_hat_D[i]).flatten())/(2-np.array(self.q_hat_D[i]).flatten())\n",
    "            else:\n",
    "                raise ValueError(\"not a valid metric\")\n",
    "            result.append(y_lower)\n",
    "            result.append(y_upper)\n",
    "        CPs = pd.DataFrame(result).T\n",
    "        CPs.rename(columns = {0:\"point_forecast\"}, inplace = True)\n",
    "        for i in range(0, 2*len(self.delta), 2):\n",
    "            d_index = round(i/2)\n",
    "            CPs.rename(columns = {i+1:\"lower_\"+str(round(self.delta[d_index]*100)), i+2:\"upper_\"+str(round(self.delta[d_index]*100))}, inplace = True)\n",
    "        return CPs"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
